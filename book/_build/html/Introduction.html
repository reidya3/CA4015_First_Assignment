
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>CA4015 Iowa Gambling Clustering Task</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-2 bd-sidebar site-navigation show single-page" id="site-navigation">
    
</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            
            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/reidya3/CA4015_Assignment_1"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/reidya3/CA4015_Assignment_1/issues/new?title=Issue%20on%20page%20%2FIntroduction.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="Introduction.html#document-Initial_Data_Exploration">
   Initial Data Exploration
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="Introduction.html#document-Clustering_Analysis">
   Cluster Analysis
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="Introduction.html#document-Federated_k_means">
   Federated K-Means
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="Introduction.html#document-Conclusion">
   Conclusion
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="Introduction.html#document-References">
   References
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<p>The Iowa Gambling task <span id="id1">[<a class="reference internal" href="Introduction.html#id20">Bechara <em>et al.</em>, 1994</a>]</span> assess real-life decision making. Developed by researchers at the University of Iowa, subjects participate in a simulated card game. Participants start with $2,000 and are presented with four card decks (A - D), with each deck more likely to yield monetary rewards or penalties over time i.e. some decks are “bad” while others are “good”. Below, A and B are considered “bad” as they have a negative expected value, while C and D are considered “good” as they are associated with a positive expected value. Test-takers obtain feedback on the amount lost or gained and the running total after each choice (trail). The subject’s goal is to adapt their pattern of choices to maximize the reward received.</p>
<p><img alt="Iowa-Gambling-Task" src="_images/iowagambling.png" /></p>
<p>In standard setups, the task typically lasts 100 trials. Empirical Investigations have shown that healthy (neurotypical) test-takers generally become aware of the “good” and “bad” decks after 20 to 40 trials <span id="id2">[<a class="reference internal" href="Introduction.html#id4">Weller <em>et al.</em>, 2010</a>]</span>. However, patients who suffer from orbitofrontal cortex (OFC) dysfunction tend to continue choosing bad decks even though the realization of continued monetary loss may have already occurred in these participants. As presented above, participants must choose advantageous long-term choices over favourable short-term picks to achieve the greatest end monetary gain. Therefore, IGT remains a popular choice to evaluate decision making and, by extension, impulsivity as it does not suffer from the self-reflection biases that questionnaires tend to display.</p>
<div class="section" id="description-of-datasets">
<h2>Description of Datasets<a class="headerlink" href="#description-of-datasets" title="Permalink to this headline">¶</a></h2>
<p>This investigation utilizes a dataset from a “many labs” initiative on the Iowa Gambling task, grouping ten studies and containing data from 617 healthy participants <span id="id3">[<a class="reference internal" href="Introduction.html#id6">Steingroever <em>et al.</em>, 2015</a>]</span>. The data consist of the choices of each participant on each trial and the resulting rewards and losses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Not all studies had the same number of trials. The number of trails varied from 95, 100 and 150.</p>
</div>
<p>The table below summarizes the multiple datasets used in this investigation.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>Labs</p></th>
<th class="text-align:right head"><p>Number of Participants</p></th>
<th class="text-align:left head"><p>Trails</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p><span id="id4">Fridberg <em>et al.</em> [<a class="reference internal" href="Introduction.html#id19">2010</a>]</span></p></td>
<td class="text-align:right"><p>15</p></td>
<td class="text-align:left"><p>95</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span id="id5">Horstmann <em>et al.</em> [<a class="reference internal" href="Introduction.html#id18">2012</a>]</span></p></td>
<td class="text-align:right"><p>162</p></td>
<td class="text-align:left"><p>100</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p><span id="id6">Kjome <em>et al.</em> [<a class="reference internal" href="Introduction.html#id17">2010</a>]</span></p></td>
<td class="text-align:right"><p>19</p></td>
<td class="text-align:left"><p>100</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span id="id7">Maia and McClelland [<a class="reference internal" href="Introduction.html#id16">2004</a>]</span></p></td>
<td class="text-align:right"><p>40</p></td>
<td class="text-align:left"><p>100</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p><span id="id8">Premkumar <em>et al.</em> [<a class="reference internal" href="Introduction.html#id15">2008</a>]</span></p></td>
<td class="text-align:right"><p>25</p></td>
<td class="text-align:left"><p>100</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span id="id9">Steingroever <em>et al.</em> [<a class="reference internal" href="Introduction.html#id13">2011</a>]</span></p></td>
<td class="text-align:right"><p>70</p></td>
<td class="text-align:left"><p>100</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p><span id="id10">Steingroever <em>et al.</em> [<a class="reference internal" href="Introduction.html#id14">2011</a>]</span></p></td>
<td class="text-align:right"><p>57</p></td>
<td class="text-align:left"><p>150</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span id="id11">Wetzels <em>et al.</em> [<a class="reference internal" href="Introduction.html#id12">2010</a>]</span></p></td>
<td class="text-align:right"><p>41</p></td>
<td class="text-align:left"><p>150</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p><span id="id12">Wood <em>et al.</em> [<a class="reference internal" href="Introduction.html#id11">2005</a>]</span></p></td>
<td class="text-align:right"><p>153</p></td>
<td class="text-align:left"><p>100</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span id="id13">Worthy <em>et al.</em> [<a class="reference internal" href="Introduction.html#id10">2013</a>]</span></p></td>
<td class="text-align:right"><p>35</p></td>
<td class="text-align:left"><p>100</p></td>
</tr>
</tbody>
</table>
<p>For further clarification of the different IGT versions used, please consult this <a class="reference external" href="http://irep.ntu.ac.uk/id/eprint/20294/1/220623_2604.pdf">paper</a>. In addition, an explanation of these datasets is provided in the Initial Data Exploration Section.</p>
<p>In this investigation, we seek to use a variety of clustering approaches to segment the participants into well-defined groups.
To start, we perform an initial data exploration to perform transformations &amp; data sanitization checks; acquire rudimentary statistics of the datasets; perform data augmentation; create exploratory visualizations. Next, we perform cluster analysis and evaluate our clusters using metrics such as Silhouette Coefficient and an Elbow curve.
These clusters represent participants that exhibit similar decision-making patterns and may have similar underlying psychological qualities such as impulsivity, stress reaction level to punishments or similar learnt experiences. Next, we attempt to form a federated k-means algorithm to preserve the privacy of the individual labs. Finally, we conclude with the most important outcomes of our work.</p>
<div class="math notranslate nohighlight">
\[\]</div>
</div>
<div class="toctree-wrapper compound">
<span id="document-Initial_Data_Exploration"></span><div class="section" id="initial-data-exploration">
<h2>Initial Data Exploration<a class="headerlink" href="#initial-data-exploration" title="Permalink to this headline">¶</a></h2>
<div class="math notranslate nohighlight">
\[\]</div>
<p>The purpose of our initial data exploration is to:</p>
<ol type = "a">
    <li>Check the validity of the data and perform data cleaning methods if needed.</li>
    <li>View the statistical details of the data</li>
    <li>Add additional data from the {cite:t}`ahn2014decision` study as we are interested in clustering unhealthy individuals</li>
    <li>Perform data visualization to improve our understanding of the data</li>
    <li>Feature Engineer</li>
    <li>Perform transformations (standardization, PCA)</li>
</ol>
<p>If you are viewing this as an HTML page, please use the content toolbar to the right for quick access to different sections.</p>
<div class="section" id="importing-required-libraries">
<h3>Importing required libraries<a class="headerlink" href="#importing-required-libraries" title="Permalink to this headline">¶</a></h3>
<p>Data processing</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<p>Data Visualization</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</pre></div>
</div>
</div>
</div>
<p>For the purposes of this exploration, we load in 12 different CSV files.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>Type</p></th>
<th class="text-align:right head"><p>File Name</p></th>
<th class="text-align:left head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>Choices</p></td>
<td class="text-align:right"><p>choices_95.csv, choices_100.csv, choices_150.csv</p></td>
<td class="text-align:left"><p>These CSV’s contains all of the choices made by test-takers during the examined studies. <strong>Note</strong>, the ten studies described in the Introduction section are grouped by the number of trails. The integer suffix of the file name indicates the number of trials performed. For example, the 1<sup>st</sup> row and 2<sup>nd</sup> column instance of the choices_95.csv file describes a participant’s 2<sup>nd</sup> card choice in a 95 trail study.</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Wins</p></td>
<td class="text-align:right"><p>wi_95.csv, wi_100.csv, wi_150.csv</p></td>
<td class="text-align:left"><p>These datasets describe the wins received by participants in 95, 100 and 150 trail investigations, as indicated by the suffix. For example, the  3<sup>rd</sup> row and 5<sup>th</sup> column entry of the wi_100.csv file details the monetary gain received by a participant on their 5<sup>th</sup> choice in 100 trail study.</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Losses</p></td>
<td class="text-align:right"><p>lo_95.csv, lo_100.csv, lo_150.csv</p></td>
<td class="text-align:left"><p>These files contain the losses received by participants in 95, 100 and 150 trail investigations, as indicated by the suffix. For example, the  2<sup>nd</sup> row and 8<sup>th</sup> column entry of the lo_150.csv file details the monetary penalty received by a participant on their 8<sup>th</sup> choice in 150 trail study.</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Index</p></td>
<td class="text-align:right"><p>index_95.csv, index_100.csv, index_150.csv</p></td>
<td class="text-align:left"><p>index_95.csv, index_100.csv, and index_150.csv map the first author of the study that reports the data to the corresponding subject.</p></td>
</tr>
</tbody>
</table>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">choice_95</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/choice_95.csv&#39;</span><span class="p">)</span>
<span class="n">choice_100</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/choice_100.csv&#39;</span><span class="p">)</span>
<span class="n">choice_150</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/choice_150.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">win_95</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/wi_95.csv&#39;</span><span class="p">)</span>
<span class="n">win_100</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/wi_100.csv&#39;</span><span class="p">)</span>
<span class="n">win_150</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/wi_150.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loss_95</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/lo_95.csv&#39;</span><span class="p">)</span>
<span class="n">loss_100</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/lo_100.csv&#39;</span><span class="p">)</span>
<span class="n">loss_150</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/lo_150.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">index_95</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/index_95.csv&#39;</span><span class="p">)</span>
<span class="n">index_100</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/index_100.csv&#39;</span><span class="p">)</span>
<span class="n">index_150</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/index_150.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Currently, the dataframes have columns in the following name format: <code class="docutils literal notranslate"><span class="pre">&lt;Description&gt;_&lt;Trial</span> <span class="pre">number&gt;</span></code> as indicated down below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Win dataframes have the following name format: </span><span class="si">{</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">win_100</span><span class="o">.</span><span class="n">columns</span><span class="p">[:</span><span class="mi">3</span><span class="p">]))</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Loss dataframes have the following name format: </span><span class="si">{</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">loss_100</span><span class="o">.</span><span class="n">columns</span><span class="p">[:</span><span class="mi">3</span><span class="p">]))</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Choice dataframes have the following name format: </span><span class="si">{</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">choice_100</span><span class="o">.</span><span class="n">columns</span><span class="p">[:</span><span class="mi">3</span><span class="p">]))</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Win dataframes have the following name format: Wins_1, Wins_2, Wins_3
Loss dataframes have the following name format: Losses_1, Losses_2, Losses_3
Choice dataframes have the following name format: Choice_1, Choice_2, Choice_3
</pre></div>
</div>
</div>
</div>
<p>For uniformity, we will replace the column names to have a <code class="docutils literal notranslate"><span class="pre">Trial_&lt;Trial</span> <span class="pre">number&gt;</span></code> format as the dataframe variable names already indicates functionality.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">column_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;trial_</span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">96</span><span class="p">)]</span>
<span class="n">choice_95</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">win_95</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">loss_95</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">column_names</span>

<span class="n">column_names</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="sa">f</span><span class="s1">&#39;trial_</span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span><span class="mi">101</span><span class="p">)])</span>
<span class="n">choice_100</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">win_100</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">loss_100</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">column_names</span>

<span class="n">column_names</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="sa">f</span><span class="s1">&#39;trial_</span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">101</span><span class="p">,</span><span class="mi">151</span><span class="p">)])</span>
<span class="n">choice_150</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">win_150</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">loss_150</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">column_names</span>

<span class="n">win_95</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>trial_1</th>
      <th>trial_2</th>
      <th>trial_3</th>
      <th>trial_4</th>
      <th>trial_5</th>
      <th>trial_6</th>
      <th>trial_7</th>
      <th>trial_8</th>
      <th>trial_9</th>
      <th>trial_10</th>
      <th>...</th>
      <th>trial_86</th>
      <th>trial_87</th>
      <th>trial_88</th>
      <th>trial_89</th>
      <th>trial_90</th>
      <th>trial_91</th>
      <th>trial_92</th>
      <th>trial_93</th>
      <th>trial_94</th>
      <th>trial_95</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Subj_1</th>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>...</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
    </tr>
    <tr>
      <th>Subj_2</th>
      <td>100</td>
      <td>100</td>
      <td>50</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>...</td>
      <td>50</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
    </tr>
    <tr>
      <th>Subj_3</th>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>...</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
    </tr>
    <tr>
      <th>Subj_4</th>
      <td>50</td>
      <td>50</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>50</td>
      <td>100</td>
      <td>100</td>
      <td>...</td>
      <td>100</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
    </tr>
    <tr>
      <th>Subj_5</th>
      <td>100</td>
      <td>100</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>100</td>
      <td>...</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
      <td>50</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 95 columns</p>
</div></div></div>
</div>
</div>
<div class="section" id="data-cleaning">
<h3>Data Cleaning<a class="headerlink" href="#data-cleaning" title="Permalink to this headline">¶</a></h3>
<p>Check for null values</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Does choice_95 contain any null values? </span><span class="si">{</span><span class="n">choice_95</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Does choice_100 contain any null values? </span><span class="si">{</span><span class="n">choice_100</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Does choice_150 contain any null values? </span><span class="si">{</span><span class="n">choice_150</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Does choice_95 contain any null values? False
Does choice_100 contain any null values? False
Does choice_150 contain any null values? False
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Does win_95 contain any null values? </span><span class="si">{</span><span class="n">win_95</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Does win_100 contain any null values? </span><span class="si">{</span><span class="n">win_100</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Does win_150 contain any null values? </span><span class="si">{</span><span class="n">win_150</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Does win_95 contain any null values? False
Does win_100 contain any null values? False
Does win_150 contain any null values? False
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Does choice_95 contain any null values? </span><span class="si">{</span><span class="n">loss_95</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Does choice_100 contain any null values? </span><span class="si">{</span><span class="n">loss_100</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Does choice_150 contain any null values? </span><span class="si">{</span><span class="n">loss_150</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Does choice_95 contain any null values? False
Does choice_100 contain any null values? False
Does choice_150 contain any null values? False
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Does index_95 contain any null values? </span><span class="si">{</span><span class="n">index_95</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Does index_100 contain any null values? </span><span class="si">{</span><span class="n">index_100</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Does index_150 contain any null values? </span><span class="si">{</span><span class="n">index_150</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Does index_95 contain any null values? False
Does index_100 contain any null values? False
Does index_150 contain any null values? False
</pre></div>
</div>
</div>
</div>
<p>This finding seems to contradict the original ‘many labs’ paper. They suggest that there should be missing data present in the 100 trial dataframes due to incompletely received datasets (i.e., missing data for one participant in
Kjome et al. study, and for two participants in Wood et al. study). However, they use the word ‘might’, so this may have been rectified since then. We also further validated this assumption by using the R programming language as the organizers provided the datasets in the rdata format. The below screenshot confirms my assumption that no missing values are present.</p>
<p><img alt="absence-of-missing-values-verified-in-r" src="_images/missing_values_verified_in_r.png" /></p>
<p>Next, we calculate the basic statistics of each data set. This is a trivial step, and it is designed to increase understanding of the problem.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># choice dataframes</span>
<span class="k">for</span> <span class="n">trial_num</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">95</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;choice_</span><span class="si">{</span><span class="n">trial_num</span><span class="si">}</span><span class="s1"> basic statistics&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s1">&#39;choice_</span><span class="si">{</span><span class="n">trial_num</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">4</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>choice_95 basic statistics
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>         trial_1    trial_2    trial_3    trial_4
count  15.000000  15.000000  15.000000  15.000000
mean    2.133333   2.333333   2.466667   2.600000
std     1.355764   0.816497   1.060099   1.183216
min     1.000000   1.000000   1.000000   1.000000
25%     1.000000   2.000000   1.500000   2.000000
50%     1.000000   2.000000   3.000000   2.000000
75%     3.500000   2.500000   3.000000   4.000000
max     4.000000   4.000000   4.000000   4.000000


choice_100 basic statistics
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>          trial_1     trial_2     trial_3     trial_4
count  504.000000  504.000000  504.000000  504.000000
mean     2.142857    2.416667    2.337302    2.434524
std      1.099172    1.092628    1.090952    1.138377
min      1.000000    1.000000    1.000000    1.000000
25%      1.000000    1.000000    1.000000    1.000000
50%      2.000000    2.000000    2.000000    2.000000
75%      3.000000    3.000000    3.000000    4.000000
max      4.000000    4.000000    4.000000    4.000000


choice_150 basic statistics
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>         trial_1    trial_2    trial_3    trial_4
count  98.000000  98.000000  98.000000  98.000000
mean    2.795918   2.663265   2.469388   2.561224
std     1.044960   1.083559   1.168346   1.175930
min     1.000000   1.000000   1.000000   1.000000
25%     2.000000   2.000000   1.000000   1.250000
50%     3.000000   3.000000   2.000000   3.000000
75%     4.000000   4.000000   4.000000   4.000000
max     4.000000   4.000000   4.000000   4.000000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># win dataframes</span>
<span class="k">for</span> <span class="n">trial_num</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">95</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;win_</span><span class="si">{</span><span class="n">trial_num</span><span class="si">}</span><span class="s1"> basic statistics&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s1">&#39;win_</span><span class="si">{</span><span class="n">trial_num</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">4</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>win_95 basic statistics
          trial_1     trial_2     trial_3     trial_4
count   15.000000   15.000000   15.000000   15.000000
mean    80.000000   86.666667   70.000000   76.666667
std     25.354628   22.886885   25.354628   25.819889
min     50.000000   50.000000   50.000000   50.000000
25%     50.000000   75.000000   50.000000   50.000000
50%    100.000000  100.000000   50.000000  100.000000
75%    100.000000  100.000000  100.000000  100.000000
max    100.000000  100.000000  100.000000  100.000000


win_100 basic statistics
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>          trial_1     trial_2     trial_3     trial_4
count  504.000000  504.000000  504.000000  504.000000
mean    81.646825   77.956349   76.636905   77.172619
std     24.124146   26.566060   25.105129   25.387493
min     50.000000   40.000000   40.000000   40.000000
25%     50.000000   50.000000   50.000000   50.000000
50%    100.000000  100.000000   80.000000   90.000000
75%    100.000000  100.000000  100.000000  100.000000
max    100.000000  120.000000  120.000000  120.000000


win_150 basic statistics
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>          trial_1     trial_2     trial_3     trial_4
count   98.000000   98.000000   98.000000   98.000000
mean    68.877551   72.959184   75.510204   74.489796
std     24.363343   25.044669   25.123302   25.123302
min     50.000000   50.000000   50.000000   50.000000
25%     50.000000   50.000000   50.000000   50.000000
50%     50.000000   50.000000  100.000000   50.000000
75%    100.000000  100.000000  100.000000  100.000000
max    100.000000  100.000000  100.000000  100.000000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># loss dataframes</span>
<span class="k">for</span> <span class="n">trial_num</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">95</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;loss_</span><span class="si">{</span><span class="n">trial_num</span><span class="si">}</span><span class="s1"> basic statistics&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s1">&#39;loss_</span><span class="si">{</span><span class="n">trial_num</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">4</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loss_95 basic statistics
       trial_1  trial_2    trial_3  trial_4
count     15.0     15.0  15.000000     15.0
mean       0.0      0.0  -3.333333      0.0
std        0.0      0.0  12.909944      0.0
min        0.0      0.0 -50.000000      0.0
25%        0.0      0.0   0.000000      0.0
50%        0.0      0.0   0.000000      0.0
75%        0.0      0.0   0.000000      0.0
max        0.0      0.0   0.000000      0.0


loss_100 basic statistics
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>           trial_1      trial_2      trial_3      trial_4
count   504.000000   504.000000   504.000000   504.000000
mean    -37.301587   -40.376984   -64.682540   -39.384921
std     149.610031   175.942949   192.871723   152.257429
min   -1250.000000 -1250.000000 -1250.000000 -1250.000000
25%       0.000000     0.000000   -50.000000     0.000000
50%       0.000000     0.000000     0.000000     0.000000
75%       0.000000     0.000000     0.000000     0.000000
max       0.000000     0.000000     0.000000     0.000000


loss_150 basic statistics
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>          trial_1      trial_2      trial_3      trial_4
count   98.000000    98.000000    98.000000    98.000000
mean   -33.673469   -64.795918   -81.122449   -88.775510
std     75.905364   191.872109   227.323661   255.509458
min   -350.000000 -1250.000000 -1250.000000 -1250.000000
25%    -50.000000   -50.000000   -50.000000   -50.000000
50%      0.000000     0.000000     0.000000     0.000000
75%      0.000000     0.000000     0.000000     0.000000
max      0.000000     0.000000     0.000000     0.000000
</pre></div>
</div>
</div>
</div>
<div class="section" id="data-augmentation">
<h4>Data Augmentation<a class="headerlink" href="#data-augmentation" title="Permalink to this headline">¶</a></h4>
<p>We are interested in how healthy vs unhealthy individuals will cluster. To this end, we include data from a study conducted by <span id="id1">Ahn <em>et al.</em> [<a class="reference internal" href="Introduction.html#id9">2014</a>]</span>. This dataset contains 48 healthy controls, 43 pure heroin and 38 pure amphetamine users.</p>
<p>Now, we perform the necessary processing steps  to ‘pivot’ the new data so that it  resembles the already created dataframes. Unfortunately not every subject had data present for all of the 100 trials. If a subject had incomplete data, they were removed from this investigation. As a result, we removed 1 healthy individual, 1 individual who takes heroin and 2 individuals who take amphetamine.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">remove_incomplete_subjects</span><span class="p">(</span><span class="n">ahn_df</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    If a subject does not have data for ALL 100 trials</span>
<span class="sd">        remove them</span>
<span class="sd">    :param ahn_df: pandas dataframe in a format devised</span>
<span class="sd">        by Ahn et al.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">subject</span> <span class="ow">in</span>  <span class="n">ahn_df</span><span class="p">[</span><span class="s2">&quot;subjID&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">():</span>
        <span class="n">subject_df</span> <span class="o">=</span> <span class="n">ahn_df</span><span class="p">[</span><span class="n">ahn_df</span><span class="p">[</span><span class="s2">&quot;subjID&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">subject</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">subject_df</span><span class="p">[</span><span class="s1">&#39;trial&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">!=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">101</span><span class="p">)):</span>
            <span class="n">ahn_df</span> <span class="o">=</span> <span class="n">ahn_df</span><span class="p">[</span><span class="n">ahn_df</span><span class="p">[</span><span class="s2">&quot;subjID&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="n">subject</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">ahn_df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ahn_healthy_100</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/IGTdata_healthy_control.txt&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">ahn_heroin_100</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/IGTdata_heroin.txt&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">ahn_amphetamine_100</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/IGTdata_amphetamine.txt&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">ahn_healthy_100</span> <span class="o">=</span> <span class="n">remove_incomplete_subjects</span><span class="p">(</span><span class="n">ahn_healthy_100</span><span class="p">)</span>
<span class="n">ahn_heroin_100</span> <span class="o">=</span> <span class="n">remove_incomplete_subjects</span><span class="p">(</span><span class="n">ahn_heroin_100</span><span class="p">)</span>
<span class="n">ahn_amphetamine_100</span> <span class="o">=</span> <span class="n">remove_incomplete_subjects</span><span class="p">(</span><span class="n">ahn_amphetamine_100</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">ahn_healthy_100</span><span class="p">[</span><span class="s2">&quot;subjID&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="o">==</span> <span class="mi">47</span>
<span class="k">assert</span> <span class="n">ahn_heroin_100</span><span class="p">[</span><span class="s2">&quot;subjID&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="o">==</span> <span class="mi">42</span>
<span class="k">assert</span> <span class="n">ahn_amphetamine_100</span><span class="p">[</span><span class="s2">&quot;subjID&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="o">==</span> <span class="mi">36</span>
</pre></div>
</div>
</div>
</div>
<p>Down below, we define two helper functions that pivot and concat data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">pivot_ahn_to_many_labs</span><span class="p">(</span><span class="n">org_df</span><span class="p">,</span> <span class="n">health_status</span><span class="p">,</span> <span class="n">selection_type</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Pivots a dataframe present in format devised by Ahn et al. to</span>
<span class="sd">    one devised by the authors of the many labs initiative</span>
<span class="sd">    </span>
<span class="sd">    :param org_dataframe: pandas dataframe in a format devised</span>
<span class="sd">        by Ahn et al.</span>
<span class="sd">    :param health_status: a variable detailing whether the subject is</span>
<span class="sd">        healthy, or takes heroin/amphetamine.</span>
<span class="sd">    :param selection_type: selection type decides do we want choices, </span>
<span class="sd">        wins or losses of the particpants.</span>
<span class="sd">        options:</span>
<span class="sd">            deck -&gt; choices</span>
<span class="sd">            gain -&gt; wins</span>
<span class="sd">            losses -&gt; losses</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">new_dataframe</span> <span class="o">=</span> <span class="n">org_df</span><span class="o">.</span><span class="n">pivot</span><span class="p">(</span>
        <span class="n">index</span><span class="o">=</span><span class="s1">&#39;subjID&#39;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s1">&#39;trial&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">rename_axis</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="n">selection_type</span><span class="p">]</span><span class="o">.</span><span class="n">rename_axis</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">new_dataframe</span> <span class="o">=</span> <span class="n">new_dataframe</span><span class="o">.</span><span class="n">add_prefix</span><span class="p">(</span><span class="s1">&#39;trial_&#39;</span><span class="p">)</span>
    <span class="n">new_dataframe</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;health status&#39;</span><span class="p">,</span> <span class="n">health_status</span><span class="p">)</span>
    <span class="n">new_dataframe</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;study&#39;</span><span class="p">,</span><span class="s1">&#39;Ahn&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_dataframe</span>
    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">concat_ahn_to_many_labs</span><span class="p">(</span> <span class="n">many_labs_df</span><span class="p">,</span> <span class="n">ahn_healthy_df</span><span class="p">,</span> <span class="n">ahn_heroin_df</span><span class="p">,</span> <span class="n">ahn_amphetamine_df</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Concats a 100 trial &#39;many labs&#39; dataframe with the dataframes provided by Ahn et al.</span>
<span class="sd">    Also, maps the health status(&#39;healthy&#39;) and the study&#39;s first author to each particpant </span>
<span class="sd">        of a many labs dataset.</span>
<span class="sd">    </span>
<span class="sd">    :param many_labs_df: Dataframe containing data from the many labs paper</span>
<span class="sd">    :param ahn_healthy_df: Contains the healthy individuals of the Ahn et al study</span>
<span class="sd">    :param ahn_heroin_df: Contains the individuals who take heroin (Ahn et al. study)</span>
<span class="sd">    :param ahn_heroin_df: Contains the individuals who take amphetamines (Ahn et al, study)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">many_labs_df</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;health status&#39;</span><span class="p">,</span> <span class="s1">&#39;healthy&#39;</span><span class="p">)</span>
    <span class="n">many_labs_df</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;study&#39;</span><span class="p">,</span> <span class="n">index_100</span><span class="p">[</span><span class="s1">&#39;Study&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">concated_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
        <span class="n">many_labs_df</span><span class="p">,</span> <span class="n">ahn_healthy_df</span><span class="p">,</span> <span class="n">ahn_heroin_df</span><span class="p">,</span> <span class="n">ahn_amphetamine_df</span>
            <span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">concated_df</span>
</pre></div>
</div>
</div>
</div>
<p>Next, we pivot the Ahn et al. data so that it follows the many labs format i.e. split by choice, win or loss.
The variable name of the pivoted datasets have the form:<code class="docutils literal notranslate"><span class="pre">ahn_{health_status}_{selection_type}_100</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ahn_healthy_choice_100</span> <span class="o">=</span> <span class="n">pivot_ahn_to_many_labs</span><span class="p">(</span><span class="n">ahn_healthy_100</span><span class="p">,</span> <span class="s1">&#39;healthy&#39;</span><span class="p">,</span> <span class="s1">&#39;deck&#39;</span><span class="p">)</span>
<span class="n">ahn_heroin_choice_100</span> <span class="o">=</span> <span class="n">pivot_ahn_to_many_labs</span><span class="p">(</span><span class="n">ahn_heroin_100</span><span class="p">,</span> <span class="s1">&#39;heroin&#39;</span><span class="p">,</span> <span class="s1">&#39;deck&#39;</span><span class="p">)</span>
<span class="n">ahn_amphetamine_choice_100</span> <span class="o">=</span> <span class="n">pivot_ahn_to_many_labs</span><span class="p">(</span><span class="n">ahn_amphetamine_100</span><span class="p">,</span> <span class="s1">&#39;amphetamine&#39;</span><span class="p">,</span> <span class="s1">&#39;deck&#39;</span><span class="p">)</span>

<span class="n">ahn_healthy_win_100</span> <span class="o">=</span> <span class="n">pivot_ahn_to_many_labs</span><span class="p">(</span><span class="n">ahn_healthy_100</span><span class="p">,</span> <span class="s1">&#39;healthy&#39;</span><span class="p">,</span> <span class="s1">&#39;gain&#39;</span><span class="p">)</span>
<span class="n">ahn_heroin_win_100</span> <span class="o">=</span> <span class="n">pivot_ahn_to_many_labs</span><span class="p">(</span><span class="n">ahn_heroin_100</span><span class="p">,</span> <span class="s1">&#39;heroin&#39;</span><span class="p">,</span> <span class="s1">&#39;gain&#39;</span><span class="p">)</span>
<span class="n">ahn_amphetamine_win_100</span> <span class="o">=</span> <span class="n">pivot_ahn_to_many_labs</span><span class="p">(</span><span class="n">ahn_amphetamine_100</span><span class="p">,</span> <span class="s1">&#39;amphetamine&#39;</span><span class="p">,</span> <span class="s1">&#39;gain&#39;</span><span class="p">)</span>

<span class="n">ahn_healthy_loss_100</span> <span class="o">=</span> <span class="n">pivot_ahn_to_many_labs</span><span class="p">(</span><span class="n">ahn_healthy_100</span><span class="p">,</span> <span class="s1">&#39;healthy&#39;</span><span class="p">,</span> <span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="n">ahn_heroin_loss_100</span> <span class="o">=</span> <span class="n">pivot_ahn_to_many_labs</span><span class="p">(</span><span class="n">ahn_heroin_100</span><span class="p">,</span> <span class="s1">&#39;heroin&#39;</span><span class="p">,</span> <span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="n">ahn_amphetamine_loss_100</span> <span class="o">=</span> <span class="n">pivot_ahn_to_many_labs</span><span class="p">(</span><span class="n">ahn_amphetamine_100</span><span class="p">,</span> <span class="s1">&#39;amphetamine&#39;</span><span class="p">,</span> <span class="s1">&#39;loss&#39;</span><span class="p">)</span>

<span class="n">ahn_healthy_choice_100</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>study</th>
      <th>health status</th>
      <th>trial_1</th>
      <th>trial_2</th>
      <th>trial_3</th>
      <th>trial_4</th>
      <th>trial_5</th>
      <th>trial_6</th>
      <th>trial_7</th>
      <th>trial_8</th>
      <th>...</th>
      <th>trial_91</th>
      <th>trial_92</th>
      <th>trial_93</th>
      <th>trial_94</th>
      <th>trial_95</th>
      <th>trial_96</th>
      <th>trial_97</th>
      <th>trial_98</th>
      <th>trial_99</th>
      <th>trial_100</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>103</th>
      <td>Ahn</td>
      <td>healthy</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>4</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>...</td>
      <td>4</td>
      <td>4</td>
      <td>4</td>
      <td>4</td>
      <td>4</td>
      <td>4</td>
      <td>4</td>
      <td>4</td>
      <td>4</td>
      <td>4</td>
    </tr>
    <tr>
      <th>104</th>
      <td>Ahn</td>
      <td>healthy</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
      <td>4</td>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>2</td>
      <td>4</td>
      <td>4</td>
      <td>2</td>
      <td>4</td>
      <td>2</td>
      <td>4</td>
      <td>2</td>
      <td>4</td>
      <td>2</td>
    </tr>
    <tr>
      <th>114</th>
      <td>Ahn</td>
      <td>healthy</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>4</td>
      <td>4</td>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>4</td>
      <td>2</td>
      <td>4</td>
      <td>4</td>
      <td>2</td>
      <td>2</td>
      <td>4</td>
      <td>2</td>
      <td>4</td>
      <td>4</td>
    </tr>
    <tr>
      <th>115</th>
      <td>Ahn</td>
      <td>healthy</td>
      <td>1</td>
      <td>3</td>
      <td>3</td>
      <td>4</td>
      <td>3</td>
      <td>4</td>
      <td>2</td>
      <td>4</td>
      <td>...</td>
      <td>1</td>
      <td>4</td>
      <td>4</td>
      <td>4</td>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>4</td>
      <td>4</td>
      <td>3</td>
    </tr>
    <tr>
      <th>116</th>
      <td>Ahn</td>
      <td>healthy</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>4</td>
      <td>4</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>3</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
      <td>3</td>
      <td>4</td>
      <td>2</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 102 columns</p>
</div></div></div>
</div>
<p>We concat the many_labs dataframe with the dataframes provided by Ahn et al. for each type (i.e. choice, win or loss).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">total_choice_100</span> <span class="o">=</span> <span class="n">concat_ahn_to_many_labs</span><span class="p">(</span><span class="n">choice_100</span><span class="p">,</span><span class="n">ahn_healthy_choice_100</span><span class="p">,</span> <span class="n">ahn_heroin_choice_100</span><span class="p">,</span> <span class="n">ahn_amphetamine_choice_100</span><span class="p">)</span>
<span class="n">total_win_100</span> <span class="o">=</span> <span class="n">concat_ahn_to_many_labs</span><span class="p">(</span><span class="n">win_100</span><span class="p">,</span><span class="n">ahn_healthy_win_100</span><span class="p">,</span> <span class="n">ahn_heroin_win_100</span><span class="p">,</span> <span class="n">ahn_amphetamine_win_100</span><span class="p">)</span>
<span class="n">total_loss_100</span> <span class="o">=</span> <span class="n">concat_ahn_to_many_labs</span><span class="p">(</span><span class="n">loss_100</span><span class="p">,</span><span class="n">ahn_healthy_loss_100</span><span class="p">,</span> <span class="n">ahn_heroin_loss_100</span><span class="p">,</span> <span class="n">ahn_amphetamine_loss_100</span><span class="p">)</span>
<span class="n">total_choice_100</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>study</th>
      <th>health status</th>
      <th>trial_1</th>
      <th>trial_2</th>
      <th>trial_3</th>
      <th>trial_4</th>
      <th>trial_5</th>
      <th>trial_6</th>
      <th>trial_7</th>
      <th>trial_8</th>
      <th>...</th>
      <th>trial_91</th>
      <th>trial_92</th>
      <th>trial_93</th>
      <th>trial_94</th>
      <th>trial_95</th>
      <th>trial_96</th>
      <th>trial_97</th>
      <th>trial_98</th>
      <th>trial_99</th>
      <th>trial_100</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Horstmann</td>
      <td>healthy</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>4</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>4</td>
      <td>2</td>
      <td>4</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Horstmann</td>
      <td>healthy</td>
      <td>2</td>
      <td>1</td>
      <td>4</td>
      <td>4</td>
      <td>3</td>
      <td>2</td>
      <td>3</td>
      <td>2</td>
      <td>...</td>
      <td>4</td>
      <td>2</td>
      <td>3</td>
      <td>4</td>
      <td>2</td>
      <td>4</td>
      <td>4</td>
      <td>2</td>
      <td>2</td>
      <td>4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Horstmann</td>
      <td>healthy</td>
      <td>4</td>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>4</td>
      <td>2</td>
      <td>4</td>
      <td>4</td>
      <td>...</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>4</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>4</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Horstmann</td>
      <td>healthy</td>
      <td>4</td>
      <td>3</td>
      <td>4</td>
      <td>2</td>
      <td>1</td>
      <td>4</td>
      <td>3</td>
      <td>2</td>
      <td>...</td>
      <td>4</td>
      <td>2</td>
      <td>3</td>
      <td>4</td>
      <td>3</td>
      <td>4</td>
      <td>1</td>
      <td>4</td>
      <td>3</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Horstmann</td>
      <td>healthy</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>3</td>
      <td>4</td>
      <td>1</td>
      <td>...</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>4</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 102 columns</p>
</div></div></div>
</div>
<p>The next two cells map the health status(‘healthy’) and study’s first author to each subject in the 95 and 150 trial studies. <strong>Note</strong>, this was completed for 100 trial studies above in the <code class="docutils literal notranslate"><span class="pre">pivot_ahn_to_many_labs()</span></code> function .</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">choice_95</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;health status&#39;</span><span class="p">,</span> <span class="s1">&#39;healthy&#39;</span><span class="p">)</span>
<span class="n">choice_95</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;study&#39;</span><span class="p">,</span> <span class="n">index_95</span><span class="p">[</span><span class="s1">&#39;Study&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">win_95</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;health status&#39;</span><span class="p">,</span> <span class="s1">&#39;healthy&#39;</span><span class="p">)</span>
<span class="n">win_95</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;study&#39;</span><span class="p">,</span> <span class="n">index_95</span><span class="p">[</span><span class="s1">&#39;Study&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">loss_95</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;health status&#39;</span><span class="p">,</span> <span class="s1">&#39;healthy&#39;</span><span class="p">)</span>
<span class="n">loss_95</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;study&#39;</span><span class="p">,</span> <span class="n">index_95</span><span class="p">[</span><span class="s1">&#39;Study&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">choice_150</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;health status&#39;</span><span class="p">,</span> <span class="s1">&#39;healthy&#39;</span><span class="p">)</span>
<span class="n">choice_150</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;study&#39;</span><span class="p">,</span> <span class="n">index_150</span><span class="p">[</span><span class="s1">&#39;Study&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">win_150</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;health status&#39;</span><span class="p">,</span> <span class="s1">&#39;healthy&#39;</span><span class="p">)</span>
<span class="n">win_150</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;study&#39;</span><span class="p">,</span> <span class="n">index_150</span><span class="p">[</span><span class="s1">&#39;Study&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">loss_150</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;health status&#39;</span><span class="p">,</span> <span class="s1">&#39;healthy&#39;</span><span class="p">)</span>
<span class="n">loss_150</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;study&#39;</span><span class="p">,</span> <span class="n">index_150</span><span class="p">[</span><span class="s1">&#39;Study&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The cumulative reward is commonly used to evaluate reinforcement learning models (RLM). This metric stems from the idea of how humans learn through interaction. RLMs attempt to be a computational approach of the same mechanism:</p>
<ul class="simple">
<li><p>A agent receives state <span class="math notranslate nohighlight">\(S_{0}\)</span> from the environment (In this case, the agent received the four decks of cards, “untouched”).</p></li>
<li><p>Based on the <span class="math notranslate nohighlight">\(S_{0}\)</span>, the agent takes an action <span class="math notranslate nohighlight">\(A_{0}\)</span>  (our agent will pick a card from deck A, B, C, or D).</p></li>
<li><p>Environment transitions to a new state <span class="math notranslate nohighlight">\(S_{1}\)</span> (our agent is present with the same deck of cards, albeit their first choice is absent).</p></li>
<li><p>Environment gives some reward <span class="math notranslate nohighlight">\(R_{1}\)</span> to the agent.</p></li>
</ul>
<p>Therefore, Cumulative reward at trial t can be defined as:</p>
<div class="math notranslate nohighlight">
\[
G(t) = \sum_{k=0}^T R_{t+k+1}
\]</div>
<p>In the same respect, we attempt to plot the cumulative reward (total) for the participants surveyed. However, given the large number of participants available, it is infeasible to plot for every subject. Therefore, we will group participants by study. When plotting, the average cumulative total at trial T for a study of N participants will be calculated as follows:</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{N} \sum_{n=1}^N\sum_{t=1}^T (W + L)_{t}
\]</div>
<p>Where W denotes the win and L denotes the loss. W is a positive integer number, whilst L is a negative integer.</p>
<p>The following code cells perform the data processing steps required to produce the visualizations. Asserts are used to test that the transformation has been performed correctly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_cumulative_reward</span><span class="p">(</span><span class="n">win_df</span><span class="p">,</span> <span class="n">loss_df</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Retrives the cumulative reward dataframe for each subject of a study.</span>
<span class="sd">    Also, sets a globals &#39;rewards&#39; variable which</span>
<span class="sd">        holds the reward at each trial for every subject of a study.</span>
<span class="sd">    :param win_df: contain the wins received by participants</span>
<span class="sd">    :param loss_df: contain the loses received by participants</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">trial_num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">win_df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span>
    <span class="c1"># Set a &#39;reward global variable&#39;, used later on in PCA </span>
    <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s1">&#39;rewards_</span><span class="si">{</span><span class="n">trial_num</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">win_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">loss_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:])</span>
    <span class="n">cum_reward</span> <span class="o">=</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s1">&#39;rewards_</span><span class="si">{</span><span class="n">trial_num</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">cum_reward</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span>
        <span class="n">win_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">],</span> <span class="n">cum_reward</span><span class="p">,</span> <span class="n">left_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
    <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s1">&#39;rewards_</span><span class="si">{</span><span class="n">trial_num</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;health status&#39;</span><span class="p">,</span> <span class="n">win_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
    <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s1">&#39;rewards_</span><span class="si">{</span><span class="n">trial_num</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;study&#39;</span><span class="p">,</span> <span class="n">win_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">cum_reward</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cum_reward_95</span> <span class="o">=</span> <span class="n">get_cumulative_reward</span><span class="p">(</span><span class="n">win_95</span><span class="p">,</span><span class="n">loss_95</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">cum_reward_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">350</span>
<span class="k">assert</span> <span class="n">cum_reward_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span> <span class="o">==</span>  <span class="mi">500</span>
<span class="k">assert</span> <span class="n">cum_reward_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span><span class="mi">69</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">450</span>

<span class="n">cum_reward_100</span> <span class="o">=</span> <span class="n">get_cumulative_reward</span><span class="p">(</span><span class="n">total_win_100</span><span class="p">,</span> <span class="n">total_loss_100</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">cum_reward_100</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">11</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1000</span>
<span class="k">assert</span> <span class="n">cum_reward_100</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">499</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span> <span class="o">==</span> <span class="mi">25</span>
<span class="k">assert</span> <span class="n">cum_reward_100</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">94</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1050</span> 

<span class="n">cum_reward_150</span> <span class="o">=</span> <span class="n">get_cumulative_reward</span><span class="p">(</span><span class="n">win_150</span><span class="p">,</span> <span class="n">loss_150</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">cum_reward_150</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">144</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1800</span>
<span class="k">assert</span> <span class="n">cum_reward_150</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">93</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span> <span class="o">==</span> <span class="mi">300</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">visualize_cumulative_reward_by_study</span><span class="p">(</span><span class="n">cum_reward_df</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    visualize the cumulative reward dataframe grouped by  study.</span>
<span class="sd">    :param cum_reward_df: contain the cumulative rewards by participants in &#39;X&#39; trial studies</span>
<span class="sd">        where &#39;X&#39; can be 95,100 and 150</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sum_cum_reward_df</span> <span class="o">=</span> <span class="n">cum_reward_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;study&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">trial_num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sum_cum_reward_df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">sum_cum_reward_df</span> <span class="o">=</span> <span class="n">sum_cum_reward_df</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">trial_num</span><span class="p">)</span>


    <span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">&#39;darkgrid&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">study</span> <span class="ow">in</span> <span class="n">sum_cum_reward_df</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
        <span class="n">end_value</span><span class="p">,</span> <span class="n">colour</span> <span class="o">=</span> <span class="n">sum_cum_reward_df</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;trial_</span><span class="si">{</span><span class="n">trial_num</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">study</span><span class="p">],</span> <span class="s1">&#39;red&#39;</span>
        <span class="k">if</span> <span class="n">end_value</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">colour</span> <span class="o">=</span><span class="s1">&#39;green&#39;</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">trial_num</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">y</span> <span class="o">=</span><span class="n">sum_cum_reward_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">study</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="n">colour</span>
                <span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Trials&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Culmatative reward ($)&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">study</span><span class="p">)</span><span class="si">}</span><span class="s2"> study (</span><span class="si">{</span><span class="n">trial_num</span><span class="si">}</span><span class="s2"> trials, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">cum_reward_df</span><span class="p">[</span><span class="n">cum_reward_df</span><span class="p">[</span><span class="s1">&#39;study&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">study</span><span class="p">])</span><span class="si">}</span><span class="s2"> participants)&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Visualizations of the <strong>average sum</strong> of the <strong>cumulative</strong> rewards, grouped by a ‘many labs’ study. Note, a green line indicates a positive end value where as a red line indicates a negative end value i.e. take home pay. Initially,we concluded that some data transformations incorrectly as our pre-conceptions were not met but ad-hoc analysis revealed no errors. However as <span id="id2">Bull <em>et al.</em> [<a class="reference internal" href="Introduction.html#id8">2015</a>]</span> notes “researchers have observed high inter-study and inter-individual variability
in IGT performance in healthy participants.”. According to <span id="id3">[<a class="reference internal" href="Introduction.html#id20">Bechara <em>et al.</em>, 1994</a>]</span>.  healthy subjects should gradually learn to choose an approximately equal number of cards from decks C and D and avoid cards from decks A and B, assuming that they focus on the long-term monetary outcome i.e. the largest take home award . Although <code class="docutils literal notranslate"><span class="pre">Steingroever2011</span></code> and <code class="docutils literal notranslate"><span class="pre">Wetzel</span></code> follow this trend, the other studies do not. This confirms our hypothesis that healthy subjects do not exclusively focus on the long-term outcome. Instead, subjects predominantly consider a combination of gain and loss frequency choices and may be influenced by psychological differences such as impulsivity or  propensity to gambling.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">visualize_cumulative_reward_by_study</span><span class="p">(</span><span class="n">cum_reward_95</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Initial_Data_Exploration_41_0.png" src="_images/Initial_Data_Exploration_41_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">visualize_cumulative_reward_by_study</span><span class="p">(</span><span class="n">cum_reward_100</span><span class="p">[</span><span class="n">cum_reward_100</span><span class="p">[</span><span class="s1">&#39;study&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;Ahn&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Initial_Data_Exploration_42_0.png" src="_images/Initial_Data_Exploration_42_0.png" />
<img alt="_images/Initial_Data_Exploration_42_1.png" src="_images/Initial_Data_Exploration_42_1.png" />
<img alt="_images/Initial_Data_Exploration_42_2.png" src="_images/Initial_Data_Exploration_42_2.png" />
<img alt="_images/Initial_Data_Exploration_42_3.png" src="_images/Initial_Data_Exploration_42_3.png" />
<img alt="_images/Initial_Data_Exploration_42_4.png" src="_images/Initial_Data_Exploration_42_4.png" />
<img alt="_images/Initial_Data_Exploration_42_5.png" src="_images/Initial_Data_Exploration_42_5.png" />
<img alt="_images/Initial_Data_Exploration_42_6.png" src="_images/Initial_Data_Exploration_42_6.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">visualize_cumulative_reward_by_study</span><span class="p">(</span><span class="n">cum_reward_150</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Initial_Data_Exploration_43_0.png" src="_images/Initial_Data_Exploration_43_0.png" />
<img alt="_images/Initial_Data_Exploration_43_1.png" src="_images/Initial_Data_Exploration_43_1.png" />
</div>
</div>
<p>A common held belief is that people who suffer from subsistence issues exhibit decision-making deficits.
These results seem to confirm this as we observed the second lowest average cumulative reward at the end trial (i.e take home award). However, although both types of substance users exhibit similar behaviour (i.e. an initial surge followed by a decline by choosing the “bad cards”)
the average heroin user tends to perform more poorly when compared to an amphetamine user. Different classes of drugs, such as stimulants and opiates might have different degree of impairment on the decision making progress.  For example, pre-cinical trails conduced by <span id="id4">Stewart <em>et al.</em> [<a class="reference internal" href="Introduction.html#id5">1984</a>]</span> describe notable differences between stimulants and opiates, which exert fundamentally different behavioral effects, such that stimulants produce arousing and activating effects, whereas opiates produce mixed inhibitory and excitatory effects. Again, this is a small sample size so results have to be interrupted with caution!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ahn_cum_reward</span> <span class="o">=</span> <span class="n">cum_reward_100</span><span class="p">[</span><span class="n">cum_reward_100</span><span class="p">[</span><span class="s1">&#39;study&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Ahn&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;health status&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">ahn_cum_reward</span> <span class="o">=</span> <span class="n">ahn_cum_reward</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">101</span><span class="p">),</span><span class="n">ahn_cum_reward</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;heroin&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;heroin&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">101</span><span class="p">),</span><span class="n">ahn_cum_reward</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;amphetamine&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;amphetamine&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;yellow&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Culmatative reward of unhealthy subjects&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Trials&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Cumulative reward ($)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Initial_Data_Exploration_45_0.png" src="_images/Initial_Data_Exploration_45_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="data-processing">
<h3>Data Processing<a class="headerlink" href="#data-processing" title="Permalink to this headline">¶</a></h3>
<p>If we were to include every feature currently available, we would have a high dimensional dataset. K-means suffers from the ‘curse of dimensionality’ as the distance metric (Euclidean distance) suffers in high dimensions.  Ah-hoc analysis using a dimensailty reduction technique known as principal component analysis (discussed later on) on the 100 trial choice dataset still revealed a high number of relevant components, 36 (Kaiser-Guttman test). This motivates us to perform feature engineering and create the following columns:</p>
<ul class="simple">
<li><p><strong>health_binary:</strong> A binary variable, 1 if the subject is healthy. Otherwise, 0</p></li>
<li><p><strong>cum_reward_25:</strong> The cumulative reward (as explained above) at trial 25. We include the cumulative reward at specified trial intervals in attempt to model the behaviour/progress of a subject when performing the task. For example, we would expect an individual that has a propensity for gambling to initially achieve well but would loose money overtime as the decks with higher wins (<span class="math notranslate nohighlight">\(100) result in a long-term net loss, while the decks with smaller wins (\)</span>50) yield a net gain</p></li>
<li><p><strong>cum_reward_50:</strong> The cumulative reward at trial 50.</p></li>
<li><p><strong>cum_reward_75:</strong> The cumulative reward at trial 57.</p></li>
<li><p><strong>cum_reward_100:</strong> The cumulative reward at trial 100.</p></li>
<li><p><strong>A:</strong> Count of the number of times card deck A (‘bad deck’) was picked.</p></li>
<li><p><strong>B:</strong> Count of the number of times card deck B (‘bad deck’) was picked.</p></li>
<li><p><strong>C:</strong> Count of the number of times card deck C (‘good deck’) was picked.</p></li>
<li><p><strong>D:</strong> Count of the number of times card deck D (‘good deck’) was picked.</p></li>
</ul>
<p>The performance of the ‘healthy’ participants on IGT may have been altered by factors that varied across the included studies (e.g. fatigue due to longer trial length). In addition, the card deck count features would be influenced by trial length and could lead to clustering by study rather than my behaviour. (However, this could have ben rectified by scaling) To mitigate against these factors and allow for more accurate comparison, we restrict our investigation to a subset of the available data (many labs + Ahn et al.). This subset contains 8 investigations, 7 that use the classical 100 trials from the ‘many labs’ paper and the <span id="id5">Ahn <em>et al.</em> [<a class="reference internal" href="Introduction.html#id9">2014</a>]</span> study. This subset includes 629 participants (age range: 18 to 88). Of those 5 studies that had information on gender, 54% were female.</p>
<p>Engineering the card occurrence columns:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">card_choice_df</span> <span class="o">=</span> <span class="n">total_choice_100</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="o">.</span><span class="n">value_counts</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">card_choice_df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;D&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Most popular card decks are B and D. This seems to contradict with the general assumption that healthy participants are only interested in long-term gain.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">deck</span> <span class="ow">in</span> <span class="n">card_choice_df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Deck </span><span class="si">{</span><span class="n">deck</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">card_choice_df</span><span class="p">[</span><span class="n">deck</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Deck A: 10103
Deck B: 19372
Deck C: 14762
Deck D: 18663
</pre></div>
</div>
</div>
</div>
<p>Engineering the cumulative reward columns:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">processed_100</span> <span class="o">=</span> <span class="n">cum_reward_100</span><span class="p">[[</span><span class="s1">&#39;study&#39;</span><span class="p">,</span><span class="s1">&#39;health status&#39;</span><span class="p">,</span> <span class="s1">&#39;trial_25&#39;</span><span class="p">,</span><span class="s1">&#39;trial_50&#39;</span><span class="p">,</span><span class="s1">&#39;trial_75&#39;</span><span class="p">,</span><span class="s1">&#39;trial_100&#39;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<p>Engineering the healthy binary column:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">processed_100</span><span class="p">[</span><span class="s1">&#39;health binary&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">processed_100</span><span class="p">[</span><span class="s1">&#39;health status&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span>  <span class="mi">1</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span><span class="s1">&#39;healthy&#39;</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">processed_100</span><span class="p">[</span><span class="n">processed_100</span><span class="p">[</span><span class="s1">&#39;health binary&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">78</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\tonyr\AppData\Local\Temp/ipykernel_22600/1793568551.py:1: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  processed_100[&#39;health binary&#39;] = processed_100[&#39;health status&#39;].apply(lambda x:  1 if x ==&#39;healthy&#39; else 0)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">processed_100</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span>
        <span class="n">processed_100</span><span class="p">,</span> <span class="n">card_choice_df</span><span class="p">,</span> <span class="n">left_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
<span class="n">processed_100</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>study</th>
      <th>health status</th>
      <th>trial_25</th>
      <th>trial_50</th>
      <th>trial_75</th>
      <th>trial_100</th>
      <th>health binary</th>
      <th>A</th>
      <th>B</th>
      <th>C</th>
      <th>D</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Horstmann</td>
      <td>healthy</td>
      <td>-250</td>
      <td>-550</td>
      <td>-800</td>
      <td>-1800</td>
      <td>1</td>
      <td>21</td>
      <td>42</td>
      <td>15</td>
      <td>22</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Horstmann</td>
      <td>healthy</td>
      <td>150</td>
      <td>-400</td>
      <td>500</td>
      <td>-800</td>
      <td>1</td>
      <td>14</td>
      <td>35</td>
      <td>18</td>
      <td>33</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Horstmann</td>
      <td>healthy</td>
      <td>-300</td>
      <td>-500</td>
      <td>-350</td>
      <td>-450</td>
      <td>1</td>
      <td>21</td>
      <td>42</td>
      <td>7</td>
      <td>30</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Horstmann</td>
      <td>healthy</td>
      <td>-450</td>
      <td>-500</td>
      <td>500</td>
      <td>1200</td>
      <td>1</td>
      <td>13</td>
      <td>24</td>
      <td>28</td>
      <td>35</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Horstmann</td>
      <td>healthy</td>
      <td>-600</td>
      <td>-700</td>
      <td>150</td>
      <td>-1300</td>
      <td>1</td>
      <td>15</td>
      <td>31</td>
      <td>28</td>
      <td>26</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="pca">
<h3>PCA<a class="headerlink" href="#pca" title="Permalink to this headline">¶</a></h3>
<p>Although standardization is typically used for features of incomparable units (e.g. height in cm and weight in kg), we will still standardize the choices and rewards due to k-means “isotropic” nature. In this case, if we left our variances unequal;  we would inversely putting more weight on features with high variance. In addition, we will perform <b>principal component analysis</b> due to avoid the curse of dimensionality that k-means can suffer from. The function of PCA is to reduce the dimensionality of a data set consisting of many variables correlated with each other, either heavily or lightly, while retaining the variation present in the data set to the maximum extent.</p>
<p>The same is done by transforming the variables (i.e. features) to a new set of variables, which are known as the <b>principal components</b>, ordered such that the retention of variation present decreases as we move down the order of components.</p>
<p>The procedure of PCA involves five steps: <br></p>
<ol class="simple">
<li><p>Standardise the data <br></p></li>
<li><p>Compute covariance matrix <br></p></li>
<li><p>Identify the eigenvalues and eigenvectors of the covariance matrix and order them according to the eigenvalues <br></p></li>
<li><p>Compute a feature vector <br></p></li>
<li><p>Recast the data <br></p></li>
</ol>
<div class="section" id="standardisation">
<h4>Standardisation<a class="headerlink" href="#standardisation" title="Permalink to this headline">¶</a></h4>
<p>We now standardize the data using the following formulae:</p>
<div class="math notranslate nohighlight">
\[
X_i = X_i - \bar{X}~~~~~~~~~~~~~~~~~~X_i = \frac{X_i}{\sigma}
\]</div>
<p>The standard deviation should equal 1 after standardization</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labeled_processed_100</span> <span class="o">=</span> <span class="n">processed_100</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,[</span><span class="s1">&#39;study&#39;</span><span class="p">,</span> <span class="s1">&#39;health status&#39;</span><span class="p">]]</span>
<span class="n">values_to_be_scaled_processed_100</span> <span class="o">=</span>  <span class="n">processed_100</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span>
<span class="n">scaled_processed_100</span>  <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">values_to_be_scaled_processed_100</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">scaled_processed_100</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<p>We will use the <code class="docutils literal notranslate"><span class="pre">PCA</span></code> function supplied by the <code class="docutils literal notranslate"><span class="pre">Scikit-learn</span></code> library for dimensionality reduction.  But how do we find the optimal number of components? Which eigenvalues are important?  The scree plot below describes the cumulative explained variance for each component. We reach 80% explained variance at the three component mark.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">scaled_processed_100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;number of components&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;cumulative explained variance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Scree plot&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Initial_Data_Exploration_62_0.png" src="_images/Initial_Data_Exploration_62_0.png" />
</div>
</div>
<p>According to the average-eigenvalue test (Kaiser-Guttman test) we should retain only those eigenvalues that are above the average which is 1.0. <br>
Jolliffe relaxes this criterium and suggest to retain eigenvalues greater than 0.7.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kasier_criterion</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s1">&#39;Kasier criterion optimal component number: </span><span class="si">{</span><span class="n">kasier_criterion</span><span class="si">}</span><span class="s1">, explained variance: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)[</span><span class="n">kasier_criterion</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span>
    <span class="p">)</span>
<span class="n">jolliffe_criterion</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s1">&#39;Jolliffe criterion optimal component number: </span><span class="si">{</span><span class="n">jolliffe_criterion</span><span class="si">}</span><span class="s1"> , expalined variance: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)[</span><span class="n">jolliffe_criterion</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Kasier criterion optimal component number: 2, explained variance: 0.7168193073625704
Jolliffe criterion optimal component number: 3 , expalined variance: 0.8117508248086707
</pre></div>
</div>
</div>
</div>
<p>For the purpose of this investigation, we decide to go with <strong>both</strong> the Kaiser criterion and Jolaliffe criterion . In addition, 2 principal components (Kasier) account for approx. 71.68% of the explained variance whilst 3 principal components (Jolliffe) account for approx. 81.17% of the explained variance.</p>
<p>Finally, we fit the <code class="docutils literal notranslate"><span class="pre">pca</span></code> model with the dataframes containing top 2 and 3 components , apply the dimensionality reduction on those respective dataframe and save the resulting dataframes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pca_2d</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">dim_reduced_2d</span> <span class="o">=</span> <span class="n">pca_2d</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">scaled_processed_100</span><span class="p">)</span>
<span class="n">dim_reduced_2d</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">dim_reduced_2d</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;component_</span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">)])</span>
<span class="n">dim_reduced_2d</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span>
        <span class="n">labeled_processed_100</span><span class="p">,</span> <span class="n">dim_reduced_2d</span><span class="p">,</span> <span class="n">left_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
<span class="n">dim_reduced_2d</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;data/dim_reduced_2d.tsv&quot;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pca_3d</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">dim_reduced_3d</span> <span class="o">=</span> <span class="n">pca_3d</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">scaled_processed_100</span><span class="p">)</span>
<span class="n">dim_reduced_3d</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">dim_reduced_3d</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;component_</span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">)])</span>
<span class="n">dim_reduced_3d</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span>
        <span class="n">labeled_processed_100</span><span class="p">,</span> <span class="n">dim_reduced_3d</span><span class="p">,</span> <span class="n">left_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
<span class="n">dim_reduced_3d</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;data/dim_reduced_3d.tsv&quot;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<span id="document-Clustering_Analysis"></span><div class="section" id="cluster-analysis">
<h2>Cluster Analysis<a class="headerlink" href="#cluster-analysis" title="Permalink to this headline">¶</a></h2>
<p>The purpose of our cluster analysis is to:</p>
<ul class="simple">
<li><p>Measure clustering &amp; central tendency.</p></li>
<li><p>Perform k-means</p></li>
<li><p>Evaluate the clusters, <strong>particularly</strong>:</p>
<ul>
<li><p>unhealthy vs healthy</p></li>
<li><p>study vs study</p></li>
</ul>
</li>
</ul>
<div class="section" id="import-libaries">
<h3>Import libaries<a class="headerlink" href="#import-libaries" title="Permalink to this headline">¶</a></h3>
<div class="section" id="data-processing">
<h4>Data Processing<a class="headerlink" href="#data-processing" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="scientific-computing">
<h4>Scientific computing<a class="headerlink" href="#scientific-computing" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span>
<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">sample</span>
<span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">uniform</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">isnan</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="clustering">
<h4>Clustering<a class="headerlink" href="#clustering" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>
<span class="kn">from</span> <span class="nn">pyclustertend</span> <span class="kn">import</span> <span class="n">ivat</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="data-visualisation">
<h4>Data Visualisation<a class="headerlink" href="#data-visualisation" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">yellowbrick.cluster</span> <span class="kn">import</span> <span class="n">SilhouetteVisualizer</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="measure-cluster-tendency">
<h3>Measure Cluster Tendency<a class="headerlink" href="#measure-cluster-tendency" title="Permalink to this headline">¶</a></h3>
<p>Clustering algorithms such as k-means are used to determine the structure of multi-dimensional data. Clusters are disjoint natural groups. However, K-means will find clusters in data even if none “actually” exist. Therefore, a fundamental question before applying any clustering algorithms is: Are clusters present at all?
We will measure the clustering tendency of both datasets before subjecting it to k-means. These datasets contain the top <strong>two principal components (2D)</strong> and the top <strong>three principal components (3D)</strong>, respectively. To do this, we employ two methods:</p>
<ul class="simple">
<li><p>Hopkins’s statistic  of randomness</p></li>
<li><p>VAT (visual assessment of tendency)</p></li>
</ul>
<div class="section" id="hopkins-statistics">
<h4>Hopkins statistics<a class="headerlink" href="#hopkins-statistics" title="Permalink to this headline">¶</a></h4>
<p>Hopkins statistics <span id="id1">[<a class="reference internal" href="Introduction.html#id7">Banerjee and Dave, 2004</a>]</span> tests the spatial randomness of a dataset i.e. it measures the probability that a given dataset aligns with a uniform distribution. It is based on the difference between the distance from a real point to its nearest neighbour, U, and the distance from a uniformly generated point within the data space to the nearest real data point, W.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(H_{0}\)</span>: The dataset <strong>is</strong> uniformly distributed</p></li>
<li><p><span class="math notranslate nohighlight">\(H_{1}\)</span>: The dataset <strong>is not</strong> uniformly distributed</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
H = \frac{\sum_{i=1}^{m} u_{i}^{d}}{\sum_{i=1}^{m} u_{i}^{d} + \sum_{i=1}^{m} w_{i}^{d}}
\]</div>
<p>If the value of the Hopkins statistic(H) is close to 1 (above 0.5), we reject <span class="math notranslate nohighlight">\(H_{0}\)</span> and can conclude that the dataset is considered significantly clusterable.  Otherwise, we fail to reject <span class="math notranslate nohighlight">\(H_{0}\)</span> and can conclude that the dataset is considered significantly uniformly distributed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">hopkins</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Hopkins statistic. Code snippet:</span>
<span class="sd">        https://matevzkunaver.wordpress.com/2017/06/20/hopkins-test-for-cluster-tendency/</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> 
    <span class="n">m</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.1</span> <span class="o">*</span> <span class="n">n</span><span class="p">)</span> 
    <span class="n">nbrs</span> <span class="o">=</span> <span class="n">NearestNeighbors</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
 
    <span class="n">rand_X</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">m</span><span class="p">)</span>
 
    <span class="n">ujd</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">wjd</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
        <span class="n">u_dist</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nbrs</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span><span class="n">uniform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span><span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">2</span><span class="p">,</span> <span class="n">return_distance</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">ujd</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">u_dist</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">w_dist</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nbrs</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">rand_X</span><span class="p">[</span><span class="n">j</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">2</span><span class="p">,</span> <span class="n">return_distance</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">wjd</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w_dist</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
 
    <span class="n">H</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ujd</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">ujd</span><span class="p">)</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">wjd</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">isnan</span><span class="p">(</span><span class="n">H</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">ujd</span><span class="p">,</span> <span class="n">wjd</span><span class="p">)</span>
        <span class="n">H</span> <span class="o">=</span> <span class="mi">0</span>
 
    <span class="k">return</span> <span class="n">H</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dim_reduced_2d</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/dim_reduced_2d.tsv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">dim_reduced_3d</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/dim_reduced_3d.tsv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>For both datasets, we reject <span class="math notranslate nohighlight">\(H_{0}\)</span> and can conclude that both datasets have a significant tendency to cluster.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;2D&#39;s hopkins statistic </span><span class="si">{</span><span class="n">hopkins</span><span class="p">(</span><span class="n">dim_reduced_2d</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:])</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;3D&#39;s hopkins statistic </span><span class="si">{</span><span class="n">hopkins</span><span class="p">(</span><span class="n">dim_reduced_3d</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:])</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2D&#39;s hopkins statistic 0.7566901952140672
3D&#39;s hopkins statistic 0.7846936678782558
</pre></div>
</div>
</div>
</div>
<div class="section" id="ivat-visual-assessment-of-tendency">
<h5>IVAT (visual assessment of tendency)<a class="headerlink" href="#ivat-visual-assessment-of-tendency" title="Permalink to this headline">¶</a></h5>
<p>VAT <span id="id2">[<a class="reference internal" href="Introduction.html#id3">Kumar and Bezdek, 2020</a>]</span> is a visual method of assessing the clustering likelihood of a dataset. VAT creates a minimum spanning tree of observations, where the pairwise distance between those observations is displayed as the black squares of an ordered dissimilarity square-shaped Map. The densely black squares on the diagonal can be understood as the number of clusters. The different shades of black provide insight on not only the numbers of clusters but also the cluster hierarchy. <strong>Note</strong>, This algorithm is not a substitute for cluster evaluation metrics (Elbow, Silhouette coefficient). It merely suggests if clusters exist in the datasets to avoid conducting cluster analysis on datasets in the first place. IVAT is just an improved version of the VAT algorithm that produces more precise images but is more computationally expensive.</p>
<p><strong>IVAT MAP 2D</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ivat</span><span class="p">(</span><span class="n">dim_reduced_2d</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Clustering_Analysis_15_0.png" src="_images/Clustering_Analysis_15_0.png" />
</div>
</div>
<p><strong>IVAT MAP 3D</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ivat</span><span class="p">(</span><span class="n">dim_reduced_3d</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Clustering_Analysis_17_0.png" src="_images/Clustering_Analysis_17_0.png" />
</div>
</div>
<p>From the result of implementing IVAT, it is observed that approximately 4 clusters are present for the 2D datatset whilst the 3D dataset remains inconclusive. However, as this algorithm is just meant to help us decide if we should go ahead with the cluster analysis or not, we will go ahead with the K-means cluster analysis as both Hopkins statistic results were significant.</p>
</div>
</div>
</div>
<div class="section" id="k-means">
<h3>K-Means<a class="headerlink" href="#k-means" title="Permalink to this headline">¶</a></h3>
<p>K-means is a common clustering algorithm. Although a simple clustering algorithm, it has vast application areas, including customer segmentation and image compression. K-means is a centroid based algorithm that aims to minimize the sum of distances between the points and their respective cluster centroid.  The main steps of this algorithm are:</p>
<ul class="simple">
<li><p><strong>Step 1</strong>: Choose the number (k) of clusters</p></li>
<li><p><strong>Step 2</strong>: Select k random points, which will become the initial centroids</p></li>
<li><p><strong>Step 3</strong>: Assign all data points to the nearest centroid.</p></li>
<li><p><strong>Step 4</strong>: Compute the centroid of the newly formed clusters by taking the
mean of data instances currently associated with that cluster.</p></li>
<li><p><strong>Step 5</strong>: Repeat steps 3 and 4 until either:</p>
<ul>
<li><p>Centroids of newly formed clusters do not change</p></li>
<li><p>Points remain in the same cluster</p></li>
<li><p>Maximum number of iterations are reached</p></li>
</ul>
</li>
</ul>
<p>But how do we find the optimal number of clusters?</p>
<ul class="simple">
<li><p>Elbow method</p></li>
<li><p>Silhouette coefficient</p></li>
</ul>
<div class="section" id="elbow-method">
<h4>Elbow method<a class="headerlink" href="#elbow-method" title="Permalink to this headline">¶</a></h4>
<p>The Elbow method calculates the error or ‘distortion’ between the data points (<span class="math notranslate nohighlight">\(y_{i}\)</span>) and their corresponding centroid (<span class="math notranslate nohighlight">\(ŷ_{i}\)</span>) of N data points for k clusters where k ⋹ {1…10}. The error metric used is the Sum of Squared Error (SSE):</p>
<div class="math notranslate nohighlight">
\[
SSE = \sum_{i=1}^{N} {(y_i - ŷ_i)^2}
\]</div>
<p>We plot these values in an attempt to find an ‘elbow’ within the curve.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Sum_of_squared_distances</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
    <span class="n">km_2d</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">km_2d</span> <span class="o">=</span> <span class="n">km_2d</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dim_reduced_2d</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:])</span>
    <span class="n">Sum_of_squared_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">km_2d</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">Sum_of_squared_distances</span><span class="p">,</span> <span class="s1">&#39;bx-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;No of Clusters&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Sum_of_squared_distances&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Elbow Method For Optimal k for 2D dataset&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Clustering_Analysis_20_0.png" src="_images/Clustering_Analysis_20_0.png" />
</div>
</div>
<p>We can see that the optimal number of clusters occur at k=2 to 4.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Sum_of_squared_distances</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
    <span class="n">km_3d</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">km_3d</span> <span class="o">=</span> <span class="n">km_3d</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dim_reduced_3d</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:])</span>
    <span class="n">Sum_of_squared_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">km_3d</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">Sum_of_squared_distances</span><span class="p">,</span> <span class="s1">&#39;bx-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;No of Clusters&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Sum_of_squared_distances&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Elbow Method For Optimal k for 3D dataset&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Clustering_Analysis_22_0.png" src="_images/Clustering_Analysis_22_0.png" />
</div>
</div>
<p>Here, determining the number of clusters is more ambiguous. Nevertheless, We believe there is a dip at k=2 to k=6 mark.</p>
</div>
</div>
<div class="section" id="sillhoute-method">
<h3>Sillhoute method<a class="headerlink" href="#sillhoute-method" title="Permalink to this headline">¶</a></h3>
<p>This method is another method of finding the correct number of clusters(k). Silhouette coefficient for a particular data point (<span class="math notranslate nohighlight">\(i\)</span>) is defined as:</p>
<div class="math notranslate nohighlight">
\[
s_{i} = \frac{b_{i} - a_{i}}{max(b_{i}, a_{i})}
\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(s_{i}\)</span>: the silhouette coefficient, ranging from -1 to 1. A score of 1 (the best) means that data point <span class="math notranslate nohighlight">\(i\)</span> is compact in its cluster and far away from other clusters. Conversely, the worst value is -1, while values near 0 denote overlapping clusters.</p></li>
<li><p><span class="math notranslate nohighlight">\(b_{i}\)</span>: average distance between <span class="math notranslate nohighlight">\(i\)</span> and all the other data points in its cluster.</p></li>
<li><p><span class="math notranslate nohighlight">\(a_{i}\)</span>: minimum average distance from <span class="math notranslate nohighlight">\(i\)</span> to all clusters to which <span class="math notranslate nohighlight">\(i\)</span> does not belong to</p></li>
</ul>
<p>We evaluate using silhouette plots. These plots display how close each point in one cluster is to points in the neighbouring clusters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">yellowbrick.cluster</span> <span class="kn">import</span> <span class="n">SilhouetteVisualizer</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span>  <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">km</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">visualizer</span> <span class="o">=</span> <span class="n">SilhouetteVisualizer</span><span class="p">(</span><span class="n">km</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;yellowbrick&#39;</span><span class="p">)</span>
    <span class="n">visualizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dim_reduced_2d</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:])</span>
    <span class="n">visualizer</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Clustering_Analysis_26_0.png" src="_images/Clustering_Analysis_26_0.png" />
<img alt="_images/Clustering_Analysis_26_1.png" src="_images/Clustering_Analysis_26_1.png" />
<img alt="_images/Clustering_Analysis_26_2.png" src="_images/Clustering_Analysis_26_2.png" />
</div>
</div>
<p>This aligns with our previous assumption that the optimal number of clusters for the 2d dataset is 3. K=4 seem to be sub-optimal due to wide fluctuations in size of the silhouette plot. The silhouette score for each cluster is above average silhouette scores when k =2, 3 or 4. However, the fluctuation in size at 3 seems to be more uniform compared to 2. Thus, we select the optimal number of clusters as 3.</p>
<p>Another method of evaluating is to simply plot the silhouette coefficient.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sill_coef</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">K</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K</span><span class="p">:</span>
    <span class="n">kmeanModel</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">kmeanModel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dim_reduced_3d</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:])</span>
    <span class="n">sill_coef</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">dim_reduced_3d</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:],</span> <span class="n">kmeanModel</span><span class="o">.</span><span class="n">labels_</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">sill_coef</span><span class="p">,</span>  <span class="n">color</span><span class="o">=</span><span class="s1">&#39;yellow&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;K&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Silhouette Coefficient for K-Means Clustering (3D dataset)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Silhouette Coefficient&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Clustering_Analysis_28_0.png" src="_images/Clustering_Analysis_28_0.png" />
</div>
</div>
<p>Here, we find the optimal number of clusters to be k=2 and 5 as these values of k maximizes the silhouette coefficient.</p>
</div>
<div class="section" id="findings">
<h3>Findings<a class="headerlink" href="#findings" title="Permalink to this headline">¶</a></h3>
<p>As mentioned previously, clusters can be considered as disjoint groups. In this context, these clusters seek to represent people with similar latent physiological processes and/or possible decision strategies. K-means clusters individuals by their choices, a health binary variable indicating if they are healthy or not and the cumulative reward at various intervals in the task. We attempt to relate the groupings to the decision-making behaviour of individual participants.</p>
<div class="section" id="top-2-principal-component-dataset">
<h4>Top 2 principal component dataset<a class="headerlink" href="#top-2-principal-component-dataset" title="Permalink to this headline">¶</a></h4>
<p>Healthy vs Unhealthy</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">km_2d</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dim_reduced_2d</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:])</span>
<span class="n">dim_reduced_2d</span><span class="p">[</span><span class="s2">&quot;clusters&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">km_2d</span><span class="o">.</span><span class="n">labels_</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;component_1&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;component_2&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">dim_reduced_2d</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;clusters&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;component_1&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;component_2&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">dim_reduced_2d</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;health status&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">)</span>
<span class="n">results_df</span> <span class="o">=</span> <span class="n">dim_reduced_2d</span><span class="p">[[</span><span class="s1">&#39;health status&#39;</span><span class="p">,</span> <span class="s1">&#39;clusters&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;health status&#39;</span><span class="p">)</span>
<span class="n">results_df</span> <span class="o">=</span> <span class="n">results_df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="o">.</span><span class="n">value_counts</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;health status&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">results_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
    </tr>
    <tr>
      <th>health status</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>amphetamine</th>
      <td>4.0</td>
      <td>4.0</td>
      <td>28.0</td>
    </tr>
    <tr>
      <th>healthy</th>
      <td>218.0</td>
      <td>201.0</td>
      <td>132.0</td>
    </tr>
    <tr>
      <th>heroin</th>
      <td>0.0</td>
      <td>5.0</td>
      <td>37.0</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="_images/Clustering_Analysis_31_1.png" src="_images/Clustering_Analysis_31_1.png" />
</div>
</div>
<p>The majority of unhealthy individuals fall in cluster 2. With the majority of healthy individuals falling in either cluster 1 and 3. Although a significant proportion also fall in cluster 2. This lines with our hypothesis that people who suffer from subsistence issues exhibit similar decision-making deficits.</p>
<p>Study vs Study</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;component_1&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;component_2&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">dim_reduced_2d</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;study&#39;</span><span class="p">)</span>
<span class="n">results_df</span> <span class="o">=</span> <span class="n">dim_reduced_2d</span><span class="p">[[</span><span class="s1">&#39;study&#39;</span><span class="p">,</span> <span class="s1">&#39;clusters&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;study&#39;</span><span class="p">)</span>
<span class="n">results_df</span> <span class="o">=</span> <span class="n">results_df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="o">.</span><span class="n">value_counts</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;study&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">results_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
    </tr>
    <tr>
      <th>study</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Ahn</th>
      <td>17.0</td>
      <td>21.0</td>
      <td>87.0</td>
    </tr>
    <tr>
      <th>Horstmann</th>
      <td>97.0</td>
      <td>57.0</td>
      <td>8.0</td>
    </tr>
    <tr>
      <th>Kjome</th>
      <td>7.0</td>
      <td>8.0</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>Maia</th>
      <td>8.0</td>
      <td>24.0</td>
      <td>8.0</td>
    </tr>
    <tr>
      <th>Premkumar</th>
      <td>3.0</td>
      <td>16.0</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>SteingroverInPrep</th>
      <td>38.0</td>
      <td>28.0</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>Wood</th>
      <td>40.0</td>
      <td>48.0</td>
      <td>65.0</td>
    </tr>
    <tr>
      <th>Worthy</th>
      <td>12.0</td>
      <td>8.0</td>
      <td>15.0</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="_images/Clustering_Analysis_33_1.png" src="_images/Clustering_Analysis_33_1.png" />
</div>
</div>
<p>Besides the Ahn and SteingroverInPrep study, participants in each study seem to be equally distributed among the clusters. If participants could be accurately clustered by study, this would suggest that their choices are due to biases in the setup of the task rather than their behaviour. However, again, this highly depends on the assumption that k-means can accurately find the clusters within this dataset.</p>
</div>
<div class="section" id="top-3-principal-component-dataset">
<h4>Top 3 principal component dataset<a class="headerlink" href="#top-3-principal-component-dataset" title="Permalink to this headline">¶</a></h4>
<p><strong>K=2</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">visualise_cluster_heat_map</span><span class="p">(</span><span class="n">focus_feature</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Visualizes the clusters as heat maps , where the squares represents </span>
<span class="sd">        the number of particpants in k clusters grouped by the focus feature </span>
<span class="sd">    </span>
<span class="sd">    :param focus_feature: focus_feature respresents the feature we want to</span>
<span class="sd">        drill down by i.e. health status or study</span>
<span class="sd">    :param k: Number of desired clusters</span>
<span class="sd">    :param df: Dataframe containing study, health status and the top 3 principal</span>
<span class="sd">        components</span>
<span class="sd">    :param cmap: matplotlib colormap name or object, or list of colors, optional</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">km_3d</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:])</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;clusters&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">km_3d</span><span class="o">.</span><span class="n">labels_</span> <span class="o">+</span> <span class="mi">1</span>
    
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="n">focus_feature</span><span class="p">,</span> <span class="s1">&#39;clusters&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">focus_feature</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="o">.</span><span class="n">value_counts</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="n">focus_feature</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;clusters&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">visualise_cluster_heat_map</span><span class="p">(</span><span class="s1">&#39;health status&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim_reduced_3d</span><span class="p">,</span> <span class="s1">&#39;Blues&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Clustering_Analysis_37_0.png" src="_images/Clustering_Analysis_37_0.png" />
</div>
</div>
<p>The healthy participants seem to be evenly spread among the two clusters. Both types of unhealthy participants have a tendency to appear in cluster 1. K-means seems to be reasonable able to cluster unhealthy patients, with 83% of unhealthy patients being clustered in the same group. However, k-means is unable to model the distinction between healthy and unhealthy individuals.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">visualise_cluster_heat_map</span><span class="p">(</span><span class="s1">&#39;study&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim_reduced_3d</span><span class="p">,</span> <span class="s1">&#39;Blues&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Clustering_Analysis_39_0.png" src="_images/Clustering_Analysis_39_0.png" />
</div>
</div>
<p>Ahn, Wood and Worthy seem to exhibit a clear preference for one cluster over another. Otherwise, participants in the other studies are reasonably evenly spread across the two clusters.</p>
<p><strong>K = 5</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">visualise_cluster_heat_map</span><span class="p">(</span><span class="s1">&#39;health status&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">dim_reduced_3d</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Clustering_Analysis_42_0.png" src="_images/Clustering_Analysis_42_0.png" />
</div>
</div>
<p>Healthy participants appear not to have a tendency to group in any cluster. For example, amphetamines users tend to group in clusters 2 and 3 and 4 whilst heroin users tend to be located in clusters 2 ,3 and 5. Interestingly, even with a more significant number of cluster’s, k-means groups the majority of unhealthy individuals in the same cluster (ie.e no distinction between opioid and stimulant dependents).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">visualise_cluster_heat_map</span><span class="p">(</span><span class="s1">&#39;study&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">dim_reduced_3d</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Clustering_Analysis_44_0.png" src="_images/Clustering_Analysis_44_0.png" />
</div>
</div>
<p>Ahn, Horstmann and Wood seem to exhibit a clear preference for one cluster over another. Otherwise, participants in the other studies are reasonably evenly spread across the five clusters. Ahn’s clustering tendency throughout this investigation is most likely due to the presence of unhealthy participants exhibiting similar decision strategies as all of the other studies only consist of healthy individuals.</p>
</div>
</div>
</div>
<span id="document-Federated_k_means"></span><div class="section" id="federated-k-means">
<h2>Federated K-Means<a class="headerlink" href="#federated-k-means" title="Permalink to this headline">¶</a></h2>
<p>In this section, we attempt to form a federated k-means algorithm to preserve the privacy of the individual labs.</p>
<p><strong>Federated learning:</strong>  First introduced by Google, federated learning trains an algorithm across multiple decentralized servers/devices with local data samples. There is <strong>no</strong> data sharing between servers. This is in contrast to the standard way of training a machine learning algorithm where all of the training dataset is uploaded to one server. This technique address critical issues relating to data privacy and security</p>
<div class="section" id="child-study">
<h3>Child (Study):<a class="headerlink" href="#child-study" title="Permalink to this headline">¶</a></h3>
<div class="section" id="base-k-means">
<h4>1. Base k-means:<a class="headerlink" href="#base-k-means" title="Permalink to this headline">¶</a></h4>
<p>The original K-Means algorithm is only trained on a given dataset once. There is no update method. In this approach, we split a study’s dataset 75:25.  75% of a study’s data is trained using normal K-means. It is important to note that all child devices are independent of one another.</p>
</div>
<div class="section" id="update">
<h4>2. Update:<a class="headerlink" href="#update" title="Permalink to this headline">¶</a></h4>
<p>In an attempt to resemble real-world federated learning where a new data point is generated on a device, we add an update step to base K-means. Rather than recompute k-means, we iterate through the remaining 25% of data and perform the following steps</p>
<ol class="simple">
<li><p>Convert new data point to NumPy array</p></li>
<li><p>Find the minimum Euclidean distance between that new point <span class="math notranslate nohighlight">\(X_{i}\)</span>  and the cluster centres (T) to find the closest cluster centre (<span class="math notranslate nohighlight">\(C_{i}\)</span>).
<span class="math notranslate nohighlight">\(
Minimum Distance = min((X_{i} - C_{1})^2.............(X_{i} - C_{T})^2)
\)</span></p></li>
<li><p>Transform the cluster centre <span class="math notranslate nohighlight">\(C_{i}\)</span> by doing the operation below. N equals the number of participants assigned to that cluster thus far i.e. before the new data point :
<span class="math notranslate nohighlight">\(
TransformedClusterCentre = \frac{((C_{i} * N) + X_{i})}{N+1}
\)</span></p></li>
<li><p>Then, the new data point is added to the cluster, and the transformed cluster centre is the new cluster centre.</p></li>
</ol>
</div>
</div>
<div class="section" id="parent-server">
<h3>Parent (Server):<a class="headerlink" href="#parent-server" title="Permalink to this headline">¶</a></h3>
<div class="section" id="aggregate-compute-weighted-average">
<h4>3. Aggregate &amp; Compute weighted average:<a class="headerlink" href="#aggregate-compute-weighted-average" title="Permalink to this headline">¶</a></h4>
<p>Once all child devices (S) have completed their update phase, their cluster centres are added to the parent server. Then, we compute another K-means run to find the optimal number of k centroids.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dim_reduced_2d</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/dim_reduced_2d.tsv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">dim_reduced_3d</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/dim_reduced_3d.tsv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here, we are just creating variables to hold the data from each study.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">studies_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Horstmann&#39;</span><span class="p">,</span> <span class="s1">&#39;Kjome&#39;</span><span class="p">,</span> <span class="s1">&#39;Maia&#39;</span><span class="p">,</span> <span class="s1">&#39;SteingroverInPrep&#39;</span><span class="p">,</span> <span class="s1">&#39;Premkumar&#39;</span><span class="p">,</span><span class="s1">&#39;Wood&#39;</span><span class="p">,</span> <span class="s1">&#39;Worthy&#39;</span><span class="p">,</span> <span class="s1">&#39;Ahn&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">study</span> <span class="ow">in</span> <span class="n">studies_list</span><span class="p">:</span>
    <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">study</span><span class="si">}</span><span class="s1">_study&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dim_reduced_2d</span><span class="p">[</span><span class="n">dim_reduced_2d</span><span class="p">[</span><span class="s1">&#39;study&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">study</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="child-k-means-class">
<h4>Child K-means class<a class="headerlink" href="#child-k-means-class" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">child_kmeans</span><span class="p">(</span><span class="n">KMeans</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A python class that executes the original k-means algorithm on 75% of the available data </span>
<span class="sd">        from a study. Leftover data is used to update the cluster centres</span>
<span class="sd">        as described above. Inherits from scikit-learn&#39;s K-means class</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                <span class="n">df</span><span class="p">,</span>
                <span class="n">n_clusters</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_df</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_df</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="mf">.25</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))])</span>
        <span class="c1"># map cluster index to number of particpants e.g. &lt;0:77&gt; </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cluster_index_num</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="c1"># map cluster index to number of particpants e.g. &lt;0:array([-0.96292967,  1.03276864])&gt; </span>
        <span class="c1"># Necessary as numpy array is unhashable </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index_cluster_centre</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

    
    <span class="k">def</span> <span class="nf">find_closest_cluster</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_data_point</span><span class="p">):</span>
        <span class="n">min_dist</span> <span class="o">=</span>  <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
        <span class="n">min_cluster_centre</span><span class="o">=</span> <span class="kc">None</span>
        <span class="n">cluster_index</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">current_key</span><span class="p">,</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">index_cluster_centre</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">current_dist</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">new_data_point</span> <span class="o">-</span> <span class="n">cluster</span><span class="p">)))</span>
            <span class="k">if</span> <span class="n">current_dist</span> <span class="o">&lt;</span> <span class="n">min_dist</span><span class="p">:</span>
                <span class="n">min_cluster_centre</span> <span class="o">=</span> <span class="n">cluster</span>
                <span class="n">min_dist</span> <span class="o">=</span> <span class="n">current_dist</span>
                <span class="n">cluster_index</span> <span class="o">=</span> <span class="n">current_key</span>
        <span class="k">return</span> <span class="n">cluster_index</span><span class="p">,</span> <span class="n">min_cluster_centre</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
            <span class="n">new_data_point</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
            <span class="n">cluster_index</span><span class="p">,</span> <span class="n">closest_cluster</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">find_closest_cluster</span><span class="p">(</span><span class="n">new_data_point</span><span class="p">)</span>
            <span class="n">num_subjects</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_index_num</span><span class="p">[</span><span class="n">cluster_index</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">index_cluster_centre</span><span class="p">[</span><span class="n">cluster_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(((</span><span class="n">closest_cluster</span> <span class="o">*</span> <span class="n">num_subjects</span><span class="p">)</span> <span class="o">+</span> <span class="n">new_data_point</span><span class="p">),</span> <span class="n">num_subjects</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cluster_index_num</span><span class="p">[</span><span class="n">cluster_index</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    

    <span class="k">def</span> <span class="nf">create_maps</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">cluster_indexes</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cluster_index_num</span> <span class="o">=</span> <span class="p">{</span><span class="n">cluster_index</span><span class="p">:</span><span class="n">count</span> <span class="k">for</span> <span class="n">cluster_index</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">cluster_indexes</span><span class="p">,</span> <span class="n">counts</span><span class="p">)</span> <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index_cluster_centre</span> <span class="o">=</span> <span class="p">{</span><span class="n">cluster_index</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[</span><span class="n">cluster_index</span><span class="p">]</span> <span class="k">for</span> <span class="n">cluster_index</span> <span class="ow">in</span> <span class="n">cluster_indexes</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_df</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">create_maps</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">()</span> 
        <span class="n">updated_cluster_centres</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">cluster_centre</span><span class="p">)</span> <span class="k">for</span> <span class="n">cluster_centre</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">index_cluster_centre</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span> 
        <span class="k">return</span> <span class="n">updated_cluster_centres</span> 
   
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="parent-k-means-class">
<h4>Parent K-means class<a class="headerlink" href="#parent-k-means-class" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">parent_kmeans</span><span class="p">(</span><span class="n">KMeans</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A python class that retrieves cluster centres from</span>
<span class="sd">        each study, and then computes another k-means algorithim </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">n_clusters</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cluster_centres_studies</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">federated_cluster_centres</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cluster_centre</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cluster_centres_studies</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">cluster_centre</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update_cluster_centre</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_centres_studies</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">get_new_centres</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_centers_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">parent_server</span> <span class="o">=</span> <span class="n">parent_kmeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="k">for</span> <span class="n">study</span> <span class="ow">in</span> <span class="n">studies_list</span><span class="p">:</span>
    <span class="c1"># First retrieving the cluster centres from a study</span>
    <span class="n">study_cluster_centres</span> <span class="o">=</span> <span class="n">child_kmeans</span><span class="p">(</span><span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">study</span><span class="si">}</span><span class="s1">_study&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:],</span> <span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="c1"># Adding that information to the parent server </span>
    <span class="n">parent_server</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">cluster_centre</span><span class="o">=</span><span class="n">study_cluster_centres</span><span class="p">)</span>

<span class="c1"># Calculating the new federated cluster centres</span>
<span class="n">parent_server</span><span class="o">.</span><span class="n">update_cluster_centre</span><span class="p">()</span>
<span class="c1"># Retreving the cluster centres from Federated K-means and normal K-means    </span>
<span class="n">fkm_cluster_centres</span> <span class="o">=</span> <span class="n">parent_server</span><span class="o">.</span><span class="n">get_new_centres</span><span class="p">()</span>
<span class="n">km_clusters_centres</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dim_reduced_2d</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:])</span><span class="o">.</span><span class="n">cluster_centers_</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="evaluation">
<h3>Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this headline">¶</a></h3>
<p>Before evaluating the results, an important consideration should be noted. As with any K-Means algorithm, results may vary with each run or input seed of the algorithm as the algorithm’s performance is heavily dependent on the initial clusters chosen. We evaluate our algorithm on the 2d dataset with k=3 and seed=42.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calulate_SSE</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">fkm_cluster_centres</span><span class="p">,</span> <span class="n">km_clusters_centres</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates k-mean&#39;s objective function (Sum Square Error) for both federared K-means</span>
<span class="sd">        algorithm and the original K-means algorithm </span>
<span class="sd">    </span>
<span class="sd">    :param df: Dataframe containing data from the many labs paper</span>
<span class="sd">    :param fkm_cluster_centres: Cluster centres of the Federated K-means Algo.</span>
<span class="sd">    :param km_clusters_centres: Cluster centres of the original K-means Algo.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;fkm_SSE&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;km_SSE&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">subject</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
        <span class="n">subject_dim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">subject</span><span class="p">[[</span><span class="s2">&quot;component_1&quot;</span><span class="p">,</span><span class="s2">&quot;component_2&quot;</span><span class="p">]])</span>
        <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="nb">min</span><span class="p">([(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">subject_dim</span> <span class="o">-</span> <span class="n">cluster</span><span class="p">)))</span> <span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">fkm_cluster_centres</span><span class="p">])</span>
        <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span>  <span class="nb">min</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">subject_dim</span> <span class="o">-</span> <span class="n">cluster</span><span class="p">))</span> <span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">km_clusters_centres</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">evaluate_2d_df</span> <span class="o">=</span> <span class="n">calulate_SSE</span><span class="p">(</span><span class="n">dim_reduced_2d</span><span class="p">,</span> <span class="n">fkm_cluster_centres</span><span class="p">,</span> <span class="n">km_clusters_centres</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Federated K-mean SSE: </span><span class="si">{</span><span class="n">evaluate_2d_df</span><span class="p">[</span><span class="s2">&quot;fkm_SSE&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;K-mean SSE: </span><span class="si">{</span><span class="n">evaluate_2d_df</span><span class="p">[</span><span class="s2">&quot;km_SSE&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Federated K-mean SSE: 1498.2800508864218
K-mean SSE: 1362.1960103577223
</pre></div>
</div>
</div>
</div>
<p>Our chosen approach only results in a approximate 10% increase in SSE compared to the original centralized K-means algorithm.</p>
</div>
</div>
<span id="document-Conclusion"></span><div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<p>In this investigation, we investigate the clustering of participants who conducted the Iowa gambling task (IGT). Engineered features included card deck choice, a health binary variable and the subject’s cumulative reward at different intervals (to monitor the balance between exploration and exploitation). In addition, we augment the existing data by adding participants from the Ahn et al. study. This enables us, to examine not only the behavioural differences between unhealthy and healthy individuals but also the varying decision-making deficiencies between opioid and stimulant dependent individuals.</p>
<p>Our most significant results are the following:</p>
<ol class="simple">
<li><p>Exploratory data analysis of the various studies contradicts the general assumption of IGT, i.e., the preference of healthy individuals to seek long-term reward. Rather than picking the two advantageous decks (C, D), ad-hoc analysis demonstrated participants generally prefer one of the advantageous (deck D) and one of the disadvantageous (deck B). Possible reasons for this observed discrepancy may be found in the particular payoff scheme of the study and the resulting inter-study biases. Alternatively, we hypothesis that healthy individuals are influenced by <strong>both</strong> long term reward and immediate gain/loss frequency.</p></li>
<li><p>Similarly, we observed a high inter-study and inter-individual variability in IGT performance in healthy participants. Participant variability could be due to divergent psychological attributes of the healthy participants such as learn behaviour, a propensity to gambling, impulsivity or different decision-making strategies. In addition, different IGT versions may explain the inter-study discrepancy.</p></li>
<li><p>Although both heroin and amphetamine users display poor decision making, the average heroin user displays a poorer take-home reward (approx. $200 difference).  Different classes of drugs might have different effects on decision-making behaviour. As mentioned previously,  pre-clinical trails concluded that stimulant and opiate users display different behavioural effects. Stimulants tend to produce arousing and activating effects. In contrast, opiates produce mixed inhibitory and excitatory effects.</p></li>
<li><p>K-means could reasonably group all unhealthy individuals into a single cluster, but healthy individuals were distributed evenly. Thus, K-means performed poorly when we examined the clusters by study. Although, this is desired!</p></li>
<li><p>The devised federated k-means algorithm resulted in a 10% increase in the sum square error.</p></li>
</ol>
<div class="section" id="future-work">
<h3>Future work<a class="headerlink" href="#future-work" title="Permalink to this headline">¶</a></h3>
<p>There are several possibilities to extend this work in future. Currently, both heroin and amphetamine addicts are grouped into the same cluster using K-means (even with different numbers of K and principal components).  We plan to experiment with hierarchical clustering algorithms that may be able to model the distinction between these subgroups in a wider ‘poor decision making’ cluster. Furthermore, sub-groups of healthy participants may be revealed with associated advantageous or disadvantageous decision behaviour.
In addition, we plan to train a reinforcement learning model on the datasets and perform clustering utilizing the parameters of that model.  Similar endeavours have shown to be fruitful, with such parameters often increasing the interoperability of results. Our devised federated k-means algorithm could also be improved by incorporating mini-batch k-means, for large local datasets or devices with low computational capacity. This would result in only a trivial reduction in accuracy and would be particularly useful if the decentralized device was a mobile phone. Finally, we are interested in incorporating other features about the subjects such as socio-economic status,  gender, and a chronic gambling addiction indicator. We hope such features might uncover specific card decision patterns or behavioural inabilities during the task.</p>
</div>
</div>
<span id="document-References"></span><div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<p id="id1"><dl class="citation">
<dt class="label" id="id9"><span class="brackets">1</span></dt>
<dd><p>Woo-Young Ahn, Georgi Vasilev, Sung-Ha Lee, Jerome R Busemeyer, John K Kruschke, Antoine Bechara, and Jasmin Vassileva. Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users. <em>Frontiers in psychology</em>, 5:849, 2014.</p>
</dd>
<dt class="label" id="id7"><span class="brackets">2</span></dt>
<dd><p>Amit Banerjee and Rajesh N Dave. Validating clusters using the hopkins statistic. In <em>2004 IEEE International conference on fuzzy systems (IEEE Cat. No. 04CH37542)</em>, volume 1, 149–153. IEEE, 2004.</p>
</dd>
<dt class="label" id="id20"><span class="brackets">3</span></dt>
<dd><p>Antoine Bechara, Antonio R Damasio, Hanna Damasio, and Steven W Anderson. Insensitivity to future consequences following damage to human prefrontal cortex. <em>Cognition</em>, 50(1-3):7–15, 1994.</p>
</dd>
<dt class="label" id="id8"><span class="brackets">4</span></dt>
<dd><p>Peter N Bull, Lynette J Tippett, and Donna Rose Addis. Decision making in healthy participants on the iowa gambling task: new insights from an operant approach. <em>Frontiers in psychology</em>, 6:391, 2015.</p>
</dd>
<dt class="label" id="id19"><span class="brackets">5</span></dt>
<dd><p>Daniel J Fridberg, Sarah Queller, Woo-Young Ahn, Woojae Kim, Anthony J Bishara, Jerome R Busemeyer, Linda Porrino, and Julie C Stout. Cognitive mechanisms underlying risky decision-making in chronic cannabis users. <em>Journal of mathematical psychology</em>, 54(1):28–38, 2010.</p>
</dd>
<dt class="label" id="id18"><span class="brackets">6</span></dt>
<dd><p>Annette Horstmann, Arno Villringer, and Jane Neumann. Iowa gambling task: there is more to consider than long-term outcome. using a linear equation model to disentangle the impact of outcome and frequency of gains and losses. <em>Frontiers in Neuroscience</em>, 6:61, 2012.</p>
</dd>
<dt class="label" id="id17"><span class="brackets">7</span></dt>
<dd><p>Kimberly L Kjome, Scott D Lane, Joy M Schmitz, Charles Green, Liangsuo Ma, Irshad Prasla, Alan C Swann, and F Gerard Moeller. Relationship between impulsivity and decision making in cocaine dependence. <em>Psychiatry research</em>, 178(2):299–304, 2010.</p>
</dd>
<dt class="label" id="id3"><span class="brackets">8</span></dt>
<dd><p>Dheeraj Kumar and James C Bezdek. Visual approaches for exploratory data analysis: a survey of the visual assessment of clustering tendency (vat) family of algorithms. <em>IEEE Systems, Man, and Cybernetics Magazine</em>, 6(2):10–48, 2020.</p>
</dd>
<dt class="label" id="id16"><span class="brackets">9</span></dt>
<dd><p>Tiago V Maia and James L McClelland. A reexamination of the evidence for the somatic marker hypothesis: what participants really know in the iowa gambling task. <em>Proceedings of the National Academy of Sciences</em>, 101(45):16075–16080, 2004.</p>
</dd>
<dt class="label" id="id15"><span class="brackets">10</span></dt>
<dd><p>Preethi Premkumar, Dominic Fannon, Elizabeth Kuipers, Andrew Simmons, Sophia Frangou, and Veena Kumari. Emotional decision-making and its dissociable components in schizophrenia and schizoaffective disorder: a behavioural and mri investigation. <em>Neuropsychologia</em>, 46(7):2002–2012, 2008.</p>
</dd>
<dt class="label" id="id6"><span class="brackets">11</span></dt>
<dd><p>Helen Steingroever, Daniel J Fridberg, Annette Horstmann, Kimberly L Kjome, Veena Kumari, Scott D Lane, Tiago V Maia, James L McClelland, Thorsten Pachur, Preethi Premkumar, and others. Data from 617 healthy participants performing the iowa gambling task: a&quot; many labs&quot; collaboration. <em>Journal of Open Psychology Data</em>, 3(1):340–353, 2015.</p>
</dd>
<dt class="label" id="id14"><span class="brackets">12</span></dt>
<dd><p>Helen Steingroever, Ruud Wetzels, and Eric-Jan Wagenmakers. Performance of healthy participants on the iowa gambling task: the impact of an alternative payoff scheme and presentation of only net outcomes. ():, 2011.</p>
</dd>
<dt class="label" id="id13"><span class="brackets">13</span></dt>
<dd><p>Martin Steingroever, Helen nd Šmíra, Michael D. Lee, and Thorsten Pachur. Do intuitive and deliberate decision makers perform differently on the iowa gambling task? ():, 2011.</p>
</dd>
<dt class="label" id="id5"><span class="brackets">14</span></dt>
<dd><p>Jane Stewart, Harriet De Wit, and Roelof Eikelboom. Role of unconditioned and conditioned drug effects in the self-administration of opiates and stimulants. <em>Psychological review</em>, 91(2):251, 1984.</p>
</dd>
<dt class="label" id="id4"><span class="brackets">15</span></dt>
<dd><p>Joshua A Weller, Irwin P Levin, and Antoine Bechara. Do individual differences in iowa gambling task performance predict adaptive decision making for risky gains and losses? <em>Journal of Clinical and Experimental Neuropsychology</em>, 32(2):141–150, 2010.</p>
</dd>
<dt class="label" id="id10"><span class="brackets">16</span></dt>
<dd><p>Darrell A Worthy, Bo Pang, and Kaileigh A Byrne. Decomposing the roles of perseveration and expected value representation in models of the iowa gambling task. <em>Frontiers in psychology</em>, 4:640, 2013.</p>
</dd>
<dt class="label" id="id12"><span class="brackets">17</span></dt>
<dd><p>Ruud Wetzels, Joachim Vandekerckhove, Francis Tuerlinckx, and Eric-Jan Wagenmakers. Bayesian parameter estimation in the expectancy valence model of the iowa gambling task. <em>Journal of Mathematical Psychology</em>, 54(1):14–27, 2010.</p>
</dd>
<dt class="label" id="id11"><span class="brackets">18</span></dt>
<dd><p>Stacey Wood, Jerome Busemeyer, Andreas Koling, Cathy R Cox, and Hasker Davis. Older adults as adaptive decision makers: evidence from the iowa gambling task. <em>Psychology and Aging</em>, 20(2):220–225, 2005.</p>
</dd>
</dl>
</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Anthony Reidy, 18369643<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>